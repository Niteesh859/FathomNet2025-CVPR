{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8f3d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:38.093330Z",
     "iopub.status.busy": "2025-05-26T13:25:38.093066Z",
     "iopub.status.idle": "2025-05-26T13:25:38.096960Z",
     "shell.execute_reply": "2025-05-26T13:25:38.096374Z"
    },
    "papermill": {
     "duration": 0.01372,
     "end_time": "2025-05-26T13:25:38.098118",
     "exception": false,
     "start_time": "2025-05-26T13:25:38.084398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r ../input/fathomnet-2025/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5050454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:38.111235Z",
     "iopub.status.busy": "2025-05-26T13:25:38.111026Z",
     "iopub.status.idle": "2025-05-26T13:25:43.407333Z",
     "shell.execute_reply": "2025-05-26T13:25:43.406518Z"
    },
    "papermill": {
     "duration": 5.304287,
     "end_time": "2025-05-26T13:25:43.408797",
     "exception": false,
     "start_time": "2025-05-26T13:25:38.104510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04e9fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:43.424058Z",
     "iopub.status.busy": "2025-05-26T13:25:43.423676Z",
     "iopub.status.idle": "2025-05-26T13:25:43.777615Z",
     "shell.execute_reply": "2025-05-26T13:25:43.777024Z"
    },
    "papermill": {
     "duration": 0.362509,
     "end_time": "2025-05-26T13:25:43.778959",
     "exception": false,
     "start_time": "2025-05-26T13:25:43.416450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_mapping = {\n",
    "    \"Vesicomyidae\": [\"Animalia\", \"Mollusca\", \"Bivalvia\", \"Veneroida\", \"Vesicomyidae\"],\n",
    "    \"Sebastolobus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastolobus\"],\n",
    "    \"Apostichopus leukothele\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Stichopodidae\", \"Apostichopus leukothele\"],\n",
    "    \"Scotoplanes\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Scotoplanes\"],\n",
    "    \"Keratoisis\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Keratoisidae\", \"Keratoisis\"],\n",
    "    \"Munnopsidae\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Isopoda\", \"Munnopsidae\"],\n",
    "    \"Scotoplanes globosa\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Scotoplanes globosa\"],\n",
    "    \"Mediaster aequalis\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Mediaster aequalis\"],\n",
    "    \"Asbestopluma monticola\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Asbestopluma\", \"Asbestopluma monticola\"],\n",
    "    \"Acanthascinae\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Valvatida\", \"Acanthasteridae\", \"Acanthascinae\"],\n",
    "    \"Florometra serratissima\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Antedonidae\", \"Florometra serratissima\"],\n",
    "    \"Psathyrometra fragilis\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Antedonidae\", \"Psathyrometra fragilis\"],\n",
    "    \"Zoantharia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Zoantharia\"],\n",
    "    \"Gersemia juliepackardae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Gersemia juliepackardae\"],\n",
    "    \"Pandalus platyceros\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Pandalidae\", \"Pandalus platyceros\"],\n",
    "    \"Isidella tentaculum\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Isidella tentaculum\"],\n",
    "    \"Holothuroidea\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\"],\n",
    "    \"Paragorgia arborea\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\", \"Paragorgia arborea\"],\n",
    "    \"Heterochone calyx\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Heterochone calyx\"],\n",
    "    \"Paragorgia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\", \"Paragorgia\"],\n",
    "    \"Terebellidae\": [\"Animalia\", \"Annelida\", \"Polychaeta\", \"Terebellida\", \"Terebellidae\"],\n",
    "    \"Ophiuroidea\": [\"Animalia\", \"Echinodermata\", \"Ophiuroidea\"],\n",
    "    \"Peniagone\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Peniagone\"],\n",
    "    \"Actiniaria\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\"],\n",
    "    \"Ceriantharia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Ceriantharia\"],\n",
    "    \"Isididae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\"],\n",
    "    \"Rathbunaster californicus\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Rathbunaster californicus\"],\n",
    "    \"Paelopatides confundens\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Paelopatides confundens\"],\n",
    "    \"Abyssocucumis abyssorum\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Aspidochirotida\", \"Stichopodidae\", \"Abyssocucumis abyssorum\"],\n",
    "    \"Strongylocentrotus fragilis\": [\"Animalia\", \"Echinodermata\", \"Echinoidea\", \"Clypeasteroida\", \"Strongylocentrotidae\", \"Strongylocentrotus fragilis\"],\n",
    "    \"Porifera\": [\"Animalia\", \"Porifera\"],\n",
    "    \"Psolus squamatus\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Stichopodidae\", \"Psolus squamatus\"],\n",
    "    \"Liponema brevicorne\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Liponema brevicorne\"],\n",
    "    \"Farrea\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Farrea\"],\n",
    "    \"Caridea\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Caridea\"],\n",
    "    \"Hexactinellida\": [\"Animalia\", \"Porifera\", \"Hexactinellida\"],\n",
    "    \"Actinernus\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Actinernus\"],\n",
    "    \"Pannychia moseleyi\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Pannychia moseleyi\"],\n",
    "    \"Gastropoda\": [\"Animalia\", \"Mollusca\", \"Gastropoda\"],\n",
    "    \"Benthocodon pedunculata\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Leptomedusae\", \"Benthocodon pedunculata\"],\n",
    "    \"Octopus rubescens\": [\"Animalia\", \"Mollusca\", \"Cephalopoda\", \"Octopodiformes\", \"Octopodidae\", \"Octopus rubescens\"],\n",
    "    \"Microstomus pacificus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Pleuronectiformes\", \"Paralichthyidae\", \"Microstomus pacificus\"],\n",
    "    \"Heteropolypus ritteri\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Hydridae\", \"Heteropolypus ritteri\"],\n",
    "    \"Parastenella\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Hydridae\", \"Parastenella\"],\n",
    "    \"Staurocalyptus\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Staurocalyptidae\", \"Staurocalyptus\"],\n",
    "    \"Hormathiidae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\", \"Hormathiidae\"],\n",
    "    \"Scleractinia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Scleractinia\"],\n",
    "    \"Asbestopluma\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Asbestopluma\"],\n",
    "    \"Isosicyonis\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Isosicyonis\"],\n",
    "    \"Umbellula\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Umbellulidae\", \"Umbellula\"],\n",
    "    \"Sebastes\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastes\"],\n",
    "    \"Metridium farcimen\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\", \"Metridiidae\", \"Metridium farcimen\"],\n",
    "    \"Merluccius productus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Gadiformes\", \"Gadidae\", \"Merluccius productus\"],\n",
    "    \"Funiculina\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Funiculinidae\", \"Funiculina\"],\n",
    "    \"Brisingida\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Brisingida\"],\n",
    "    \"Pyrosoma atlanticum\": [\"Animalia\", \"Chordata\", \"Tunicates\", \"Pyrosomida\", \"Pyrosomatidae\", \"Pyrosoma atlanticum\"],\n",
    "    \"Acanthoptilum\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Perciformes\", \"Acanthoptilidae\", \"Acanthoptilum\"],\n",
    "    \"Actinopterygii\": [\"Animalia\", \"Chordata\", \"Actinopterygii\"],\n",
    "    \"Chorilia longipes\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Chorilia longipes\"],\n",
    "    \"Paralomis multispina\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Lithodidae\", \"Paralomis multispina\"],\n",
    "    \"Sebastes diploproa\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastes diploproa\"],\n",
    "    \"Mycale\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Mycale\"],\n",
    "    \"Lithodidae\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Lithodidae\"],\n",
    "    \"Ophiacanthidae\": [\"Animalia\", \"Echinodermata\", \"Ophiuroidea\", \"Ophiacanthidae\"],\n",
    "    \"Corallimorphus pilatus\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Corallimorpharia\", \"Corallimorphidae\", \"Corallimorphus pilatus\"],\n",
    "    \"Ptychogastria polaris\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidea\", \"Ptychogastriidae\", \"Ptychogastria polaris\"],\n",
    "    \"Amphipoda\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Amphipoda\"],\n",
    "    \"Heterocarpus\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Heterocarpoidea\", \"Heterocarpus\"],\n",
    "    \"Pennatula phosphorea\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Pennatulacea\", \"Pennatulidae\", \"Pennatula phosphorea\"],\n",
    "    \"Chionoecetes tanneri\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Oregoniidae\", \"Chionoecetes tanneri\"],\n",
    "    \"Hippasteria\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Valvatida\", \"Asteriidae\", \"Hippasteria\"],\n",
    "    \"Munidopsis\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Munidopsidae\", \"Munidopsis\"],\n",
    "    \"Serpulidae\": [\"Animalia\", \"Annelida\", \"Polychaeta\", \"Canalipalpata\", \"Serpulidae\"],\n",
    "    \"Delectopecten\": [\"Animalia\", \"Mollusca\", \"Bivalvia\", \"Pectinida\", \"Pectinidae\", \"Delectopecten\"],\n",
    "    \"Crinoidea\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\"],\n",
    "    \"Tunicata\": [\"Animalia\", \"Chordata\", \"Tunicata\"],\n",
    "    \"Asteroidea\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\"],\n",
    "    \"Pandalus amplus\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Pandalidae\", \"Pandalus amplus\"],\n",
    "    \"Elpidia\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Aspidochirotida\", \"Stichopodidae\", \"Elpidia\"]\n",
    "}\n",
    "import json\n",
    "with open('/kaggle/input/fathomnet-2025/dataset_train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "id_to_name = {i: category['name'] for i, category in enumerate(data['categories'])}\n",
    "keys = list(tree_mapping.keys())\n",
    "k = 0\n",
    "for i in range(len(keys)):\n",
    "    k = max(len(tree_mapping[keys[i]]), k)\n",
    "for i in range(len(keys)):\n",
    "    tree_mapping[keys[i]].append(\"spl_stp\")\n",
    "    tree_mapping[keys[i]] += [\"-\"] * (7 - len(tree_mapping[keys[i]]))\n",
    "\n",
    "columns = [\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus_Species\", \"spl\"]\n",
    "df = pd.DataFrame.from_dict(tree_mapping, orient='index', columns=columns)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Taxon'}, inplace=True)\n",
    "unique_elements = pd.unique(df.values.ravel())\n",
    "onehot = dict(pd.get_dummies(unique_elements).astype(int))\n",
    "for i in range(len(list(tree_mapping.keys()))):\n",
    "    for j in range(7):\n",
    "        tree_mapping[list(tree_mapping.keys())[i]][j] = onehot[tree_mapping[list(tree_mapping.keys())[i]][j]]\n",
    "labels_idx = [int(torch.tensor(onehot[i]).argmax()) for i in id_to_name.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e1de74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:43.792180Z",
     "iopub.status.busy": "2025-05-26T13:25:43.791937Z",
     "iopub.status.idle": "2025-05-26T13:25:48.600389Z",
     "shell.execute_reply": "2025-05-26T13:25:48.599600Z"
    },
    "papermill": {
     "duration": 4.816567,
     "end_time": "2025-05-26T13:25:48.601794",
     "exception": false,
     "start_time": "2025-05-26T13:25:43.785227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = val_transforms  # identical to val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38522b1",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2025-05-26T13:25:48.614280",
     "exception": false,
     "start_time": "2025-05-26T13:25:48.608195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------------**DataSet Classes**-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d843235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:48.627516Z",
     "iopub.status.busy": "2025-05-26T13:25:48.626676Z",
     "iopub.status.idle": "2025-05-26T13:25:48.631705Z",
     "shell.execute_reply": "2025-05-26T13:25:48.630983Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012781,
     "end_time": "2025-05-26T13:25:48.632901",
     "exception": false,
     "start_time": "2025-05-26T13:25:48.620120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# import ast\n",
    "\n",
    "\n",
    "# class FathomNetDataset_tkn(Dataset):\n",
    "#     def __init__(self, csv_path, transformation=None, is_test=False, tree_map=tree_mapping):\n",
    "#         self.data = pd.read_csv(csv_path)\n",
    "#         self.transform = transformation\n",
    "#         self.is_test = is_test\n",
    "#         self.image_paths = self.data[\"path\"].tolist()\n",
    "#         self.num_class = len(list(tree_map.keys()))\n",
    "\n",
    "#         if not is_test:\n",
    "#             self.labels = self.data[\"label\"]\n",
    "#             # one_hot = pd.get_dummies(self.labels)\n",
    "#             self.updated_labels = self.labels.map(lambda x: tree_mapping[x])\n",
    "#             # self.class_mapping = dict(enumerate(one_hot.columns.tolist()))\n",
    "#             # self.class_mapping = tree_map\n",
    "#         else:\n",
    "#             self.labels = None\n",
    "#             self.label_encoded = None\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "#         img_trans = self.transform(img) if self.transform else img\n",
    "    \n",
    "#         if self.is_test:\n",
    "#             return img_trans, self.image_paths[idx]\n",
    "#         else:\n",
    "#             label = self.updated_labels[idx]\n",
    "#             label_tensor = torch.tensor(label)\n",
    "#             return img_trans, label_tensor\n",
    "\n",
    "# class FathomNetDataset_indep(Dataset):\n",
    "\n",
    "#     def __init__(self, csv_path, transform=None, label_encoder=None, is_test=False):\n",
    "#         self.data = pd.read_csv(csv_path)\n",
    "#         self.transform = transform\n",
    "#         self.is_test = is_test\n",
    "\n",
    "#         self.image_paths = self.data[\"path\"].tolist()\n",
    "\n",
    "#         if not is_test:\n",
    "#             self.labels = self.data[\"label\"].tolist()\n",
    "#             # Use provided label encoder or fit one\n",
    "#             if label_encoder is None:\n",
    "#                 self.label_encoder = LabelEncoder()\n",
    "#                 self.label_ids = self.label_encoder.fit_transform(self.labels)\n",
    "#             else:\n",
    "#                 self.label_encoder = label_encoder\n",
    "#                 self.label_ids = self.label_encoder.transform(self.labels)\n",
    "#         else:\n",
    "#             self.labels = None\n",
    "#             self.label_ids = None\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         if self.is_test:\n",
    "#             return image, self.image_paths[idx]\n",
    "#         else:\n",
    "#             label = self.label_ids[idx]\n",
    "#             return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f588dd9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:48.645628Z",
     "iopub.status.busy": "2025-05-26T13:25:48.645259Z",
     "iopub.status.idle": "2025-05-26T13:25:48.652945Z",
     "shell.execute_reply": "2025-05-26T13:25:48.652378Z"
    },
    "papermill": {
     "duration": 0.01514,
     "end_time": "2025-05-26T13:25:48.653986",
     "exception": false,
     "start_time": "2025-05-26T13:25:48.638846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "class FathomNetDataset_tkn(Dataset):\n",
    "    def __init__(self, csv_path, transformation=None, is_test=False):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transformation\n",
    "        self.is_test = is_test\n",
    "        self.image_paths = self.data[\"path\"].tolist()\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.labels = self.data[\"label\"].tolist()\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.is_test:\n",
    "            return img, self.image_paths[idx]\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "\n",
    "\n",
    "class FathomNetDataset_indep(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, is_test=False, label_encoder=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.image_paths = self.data[\"path\"].tolist()\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.labels = self.data[\"label\"].tolist()\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image, self.image_paths[idx]\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2cae8",
   "metadata": {
    "papermill": {
     "duration": 0.006234,
     "end_time": "2025-05-26T13:25:48.666286",
     "exception": false,
     "start_time": "2025-05-26T13:25:48.660052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------------------**Model Classes**--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325c70e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:48.679637Z",
     "iopub.status.busy": "2025-05-26T13:25:48.679422Z",
     "iopub.status.idle": "2025-05-26T13:25:52.312938Z",
     "shell.execute_reply": "2025-05-26T13:25:52.312217Z"
    },
    "papermill": {
     "duration": 3.64222,
     "end_time": "2025-05-26T13:25:52.314312",
     "exception": false,
     "start_time": "2025-05-26T13:25:48.672092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N-ary Tree LSTM\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import EfficientNet_V2_M_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "class ChildSumTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.child_num = max_len  # max number of children\n",
    "\n",
    "        # Input projections\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Distinct hidden projections per child (indexed by position)\n",
    "        self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "        # Bias terms\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, child_h, child_c):\n",
    "        # Pad child_h and child_c with zeros up to self.child_num\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        # Fill missing child states\n",
    "        child_h = child_h + [zero_h] * (self.child_num - len(child_h))\n",
    "        child_c = child_c + [zero_c] * (self.child_num - len(child_c))\n",
    "\n",
    "        # Sum over active children only (i.e., up to original len)\n",
    "        active_len = len(child_h) - (self.child_num - len(child_h))\n",
    "\n",
    "        # Gates\n",
    "        i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(active_len)) + self.b_i\n",
    "        o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(active_len)) + self.b_o\n",
    "        u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(active_len)) + self.b_u\n",
    "\n",
    "        i = torch.sigmoid(i_input)\n",
    "        o = torch.sigmoid(o_input)\n",
    "        u = torch.tanh(u_input)\n",
    "\n",
    "        # Forget gates and new cell state\n",
    "        c = i * u\n",
    "        for k in range(active_len):\n",
    "            f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "            c += f_k * child_c[k]\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class FathomnetClassTree(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn_idx = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # EfficientNet feature extractor\n",
    "        base = models.efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            base.features,\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Project image features to LSTM hidden size\n",
    "        self.img_proj = nn.Linear(input_dim, hidden_size)\n",
    "\n",
    "        # TreeLSTM cell (shared across time)\n",
    "        self.tree_cell = ChildSumTreeLSTMCell(input_size=input_dim, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "        # Final classifier head\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "\n",
    "        # 1. Extract image features\n",
    "        feats = self.feature_extractor(x)  # [B, input_dim]\n",
    "        img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "        img_c = torch.zeros_like(img_h)\n",
    "\n",
    "        # 2. Init state\n",
    "        hidden_states = [img_h]\n",
    "        cell_states = [img_c]\n",
    "        logits_list = []\n",
    "\n",
    "        done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        # 3. Decode for max_len steps\n",
    "        for t in range(self.max_len):\n",
    "            h_t, c_t = self.tree_cell(feats, hidden_states, cell_states)\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "\n",
    "            logits = self.fc(h_t)  # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            done |= (preds == self.stop_tkn_idx)\n",
    "            if done.all():\n",
    "                break\n",
    "\n",
    "        # 4. Padding if needed\n",
    "        output = torch.cat(logits_list, dim=1)\n",
    "        pad_len = self.max_len - output.size(1)\n",
    "        if pad_len > 0:\n",
    "            pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, self.pad_tkn_idx] = 1  # Add one-hot pad probs\n",
    "            output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "        return output  # [B, max_len, vocab_size]\n",
    "\n",
    "    def criterion(self, x, y):\n",
    "        logits = self.forward(x)                   # [B, 7, V]\n",
    "        y = y.float()                              # [B, 7, V]\n",
    "        logits_flat = logits.view(-1, self.vocab_size)\n",
    "        targets_flat = y.view(-1, self.vocab_size)\n",
    "        return self.loss(logits_flat, targets_flat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FathomnetClassLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        # Feature extractor\n",
    "        self.model = models.efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            self.model.features,\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # GRU decoder (changed from LSTM to GRU)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # Direct index assignment from known tensors\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lambda_path = 0.3\n",
    "\n",
    "        # Loss function ignoring padding tokens\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        feats = self.feature_extractor(x)              # [B, input_dim]\n",
    "        input_seq = feats.unsqueeze(1)                 # [B, 1, input_dim]\n",
    "\n",
    "        hidden = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        cell   = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        logits_list = []                               # [B, t, V]\n",
    "        done = [False] * batch_size\n",
    "\n",
    "        for t in range(self.max_len):\n",
    "            out, (hidden, cell) = self.lstm(input_seq, (hidden, cell))  # [B,1,H]\n",
    "            logits = self.fc(out.squeeze(1))                             # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))                      # [B,1,V]\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)                          # [B]\n",
    "            for i in range(batch_size):\n",
    "                if not done[i] and preds[i].item() == 5:\n",
    "                    done[i] = True\n",
    "            if all(done):\n",
    "                break\n",
    "\n",
    "            input_seq = feats.unsqueeze(1)\n",
    "\n",
    "        logits_tensor = torch.cat(logits_list, dim=1)  # [B, T_pred, V]; Here T-pred is varible <= 7\n",
    "        # pad to max_len\n",
    "        if logits_tensor.size(1) < self.max_len:\n",
    "            pad_size = self.max_len - logits_tensor.size(1)\n",
    "            pad_logits = torch.zeros(batch_size, pad_size, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, 6] = 1\n",
    "            logits_tensor = torch.cat([logits_tensor, pad_logits], dim=1)\n",
    "\n",
    "        return logits_tensor   #[B, 7, V]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FathomnetClass(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FathomnetClass, self).__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNetV2-M backbone\n",
    "        self.backbone = models.efficientnet_v2_m(weights=models.EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        \n",
    "        # Replace the classifier head\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 48),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(48, num_classes)\n",
    "        )\n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def compute_loss(self, x, labels):\n",
    "        \"\"\"Returns loss and logits.\"\"\"\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "class ChildSumTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.child_num = max_len\n",
    "\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, child_h, child_c):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        actual_len = len(child_h)\n",
    "        child_h = child_h + [zero_h] * (self.child_num - actual_len)\n",
    "        child_c = child_c + [zero_c] * (self.child_num - actual_len)\n",
    "\n",
    "        i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(actual_len)) + self.b_i\n",
    "        o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(actual_len)) + self.b_o\n",
    "        u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(actual_len)) + self.b_u\n",
    "\n",
    "        i = torch.sigmoid(i_input)\n",
    "        o = torch.sigmoid(o_input)\n",
    "        u = torch.tanh(u_input)\n",
    "\n",
    "        c = i * u\n",
    "        for k in range(actual_len):\n",
    "            f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "            c += f_k * child_c[k]\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class FathomnetClassResnet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn_idx = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # EfficientNet backbone\n",
    "        backbone = timm.create_model(\"resnest269e\", pretrained=True, num_classes=0)  # num_classes=0 disables classifier\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            backbone,  # full model will just return features\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        feat_dim = backbone.num_features  # e.g., 1280 for B0\n",
    "\n",
    "        self.img_proj = nn.Linear(feat_dim, hidden_size)\n",
    "\n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.start_token = nn.Parameter(torch.randn(1, hidden_size))\n",
    "\n",
    "        # TreeLSTM\n",
    "        self.tree_cell = ChildSumTreeLSTMCell(input_size=hidden_size, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "\n",
    "        # 1. Encode image\n",
    "        feats = self.feature_extractor(x)  # [B, feat_dim]\n",
    "        img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "        img_c = torch.zeros_like(img_h)\n",
    "\n",
    "        hidden_states = [img_h]\n",
    "        cell_states = [img_c]\n",
    "        logits_list = []\n",
    "\n",
    "        done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        current_token = self.start_token.expand(batch_size, -1)\n",
    "\n",
    "        for t in range(self.max_len):\n",
    "            h_t, c_t = self.tree_cell(current_token, hidden_states, cell_states)\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "\n",
    "            logits = self.fc(h_t)  # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "            if targets is not None:\n",
    "                # Teacher forcing\n",
    "                current_token = self.token_emb(targets[:, t])\n",
    "            else:\n",
    "                # Inference\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                done |= (preds == self.stop_tkn_idx)\n",
    "                current_token = self.token_emb(preds)\n",
    "                if done.all():\n",
    "                    break\n",
    "\n",
    "        output = torch.cat(logits_list, dim=1)\n",
    "\n",
    "        if targets is not None:\n",
    "            loss = self.loss(output.view(-1, self.vocab_size), targets.view(-1))\n",
    "            return output, loss\n",
    "\n",
    "        # Pad if needed\n",
    "        pad_len = self.max_len - output.size(1)\n",
    "        if pad_len > 0:\n",
    "            pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, self.pad_tkn_idx] = 1\n",
    "            output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "        return output  # [B, max_len, vocab_size]\n",
    "\n",
    "\n",
    "\n",
    "# Swin Transformer Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import timm  # for ResNeST backbone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # for progress bars\n",
    "\n",
    "\n",
    "class ChildSumTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.child_num = max_len\n",
    "\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, child_h, child_c):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        actual_len = len(child_h)\n",
    "        child_h = child_h + [zero_h] * (self.child_num - actual_len)\n",
    "        child_c = child_c + [zero_c] * (self.child_num - actual_len)\n",
    "\n",
    "        i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(actual_len)) + self.b_i\n",
    "        o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(actual_len)) + self.b_o\n",
    "        u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(actual_len)) + self.b_u\n",
    "\n",
    "        i = torch.sigmoid(i_input)\n",
    "        o = torch.sigmoid(o_input)\n",
    "        u = torch.tanh(u_input)\n",
    "\n",
    "        c = i * u\n",
    "        for k in range(actual_len):\n",
    "            f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "            c += f_k * child_c[k]\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class FathomnetClassSwin(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn_idx = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # EfficientNet backbone\n",
    "        backbone = timm.create_model(\"swin_large_patch4_window7_224\", pretrained=True, num_classes=0)  # num_classes=0 disables classifier\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            backbone,  # full model will just return features\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        feat_dim = backbone.num_features    # [batch_size, 1536]\n",
    "\n",
    "        self.img_proj = nn.Linear(feat_dim, hidden_size)\n",
    "\n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.start_token = nn.Parameter(torch.randn(1, hidden_size))\n",
    "\n",
    "        # TreeLSTM\n",
    "        self.tree_cell = ChildSumTreeLSTMCell(input_size=hidden_size, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "\n",
    "        # 1. Encode image\n",
    "        feats = self.feature_extractor(x)  # [B, feat_dim]\n",
    "        img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "        img_c = torch.zeros_like(img_h)\n",
    "\n",
    "        hidden_states = [img_h]\n",
    "        cell_states = [img_c]\n",
    "        logits_list = []\n",
    "\n",
    "        done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        current_token = self.start_token.expand(batch_size, -1)\n",
    "\n",
    "        for t in range(self.max_len):\n",
    "            h_t, c_t = self.tree_cell(current_token, hidden_states, cell_states)\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "\n",
    "            logits = self.fc(h_t)  # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "            if targets is not None:\n",
    "                # Teacher forcing\n",
    "                current_token = self.token_emb(targets[:, t])\n",
    "            else:\n",
    "                # Inference\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                done |= (preds == self.stop_tkn_idx)\n",
    "                current_token = self.token_emb(preds)\n",
    "                if done.all():\n",
    "                    break\n",
    "\n",
    "        output = torch.cat(logits_list, dim=1)\n",
    "\n",
    "        if targets is not None:\n",
    "            loss = self.loss(output.view(-1, self.vocab_size), targets.view(-1))\n",
    "            return output, loss\n",
    "\n",
    "        # Pad if needed\n",
    "        pad_len = self.max_len - output.size(1)\n",
    "        if pad_len > 0:\n",
    "            pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, self.pad_tkn_idx] = 1\n",
    "            output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "        return output  # [B, max_len, vocab_size]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# # ---------------------------\n",
    "# # Meta-learner model definition\n",
    "# # ---------------------------\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class MetaLearnerTokenWise(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  in_channels=3,      # number of base models\n",
    "#                  num_classes=79,     # number of classes (treated as tokens)\n",
    "#                  d_model=128,        # embedding dim per token\n",
    "#                  nhead=4,\n",
    "#                  num_layers=2,\n",
    "#                  dropout=0.3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # 1x1 Conv1d to project model outputs per token to d_model\n",
    "#         self.conv_in = nn.Conv1d(in_channels, d_model, kernel_size=1)\n",
    "\n",
    "#         # Positional embeddings for each class position (token)\n",
    "#         self.pos_embedding = nn.Parameter(torch.randn(1, num_classes, d_model))\n",
    "\n",
    "#         # Transformer encoder layers\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "#         # Final linear layer per token to predict class logits\n",
    "#         self.fc_out = nn.Linear(d_model, 1)  # Output 1 logit per token (per class)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         x: [B, in_channels=3, num_classes=79]\n",
    "#         Output: [B, num_classes] logits (one per class)\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Input shape: [B, channels=3, length=79]\n",
    "#         # Project channels -> d_model dim space\n",
    "#         x = self.conv_in(x)  # [B, d_model, 79]\n",
    "\n",
    "#         # Transformer expects [seq_len, batch, feature], so permute:\n",
    "#         x = x.permute(2, 0, 1)  # [79, B, d_model]\n",
    "\n",
    "#         # Add positional embeddings\n",
    "#         pos_emb = self.pos_embedding.permute(1, 0, 2)  # [79, 1, d_model]\n",
    "#         x = x + pos_emb  # broadcast along batch\n",
    "\n",
    "#         # Pass through Transformer encoder\n",
    "#         x = self.transformer_encoder(x)  # [79, B, d_model]\n",
    "\n",
    "#         # Permute back: [B, 79, d_model]\n",
    "#         x = x.permute(1, 0, 2)\n",
    "\n",
    "#         # Predict a single logit per token (class)\n",
    "#         logits = self.fc_out(x).squeeze(-1)  # [B, 79]\n",
    "\n",
    "#         return logits\n",
    "\n",
    "\n",
    "\n",
    "# # class MetaLearnerAttention(nn.Module):\n",
    "# #     def __init__(self, feature_dim=79, num_classes=2):\n",
    "# #         super(MetaLearnerAttention, self).__init__()\n",
    "# #         self.attn = nn.MultiheadAttention(embed_dim=79, num_heads=1, batch_first=True)\n",
    "# #         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "# #         self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "# #     def forward(self, x):  # x: [batch, 3, 79]\n",
    "# #         attn_out, _ = self.attn(x, x, x)  # shape: [batch, 3, 79]\n",
    "# #         pooled = self.pool(attn_out.transpose(1, 2))  # -> [batch, 79, 1] → avg over 3 → [batch, 79, 1]\n",
    "# #         out = self.fc(pooled.squeeze(-1))  # [batch, 79] → [batch, num_classes]\n",
    "# #         return out\n",
    "\n",
    "# # class MetaLearnerAttention(nn.Module):\n",
    "# #     def __init__(self, feature_dim=79, num_classes=2):\n",
    "# #         super(MetaLearnerAttention, self).__init__()\n",
    "# #         self.attn = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=1, batch_first=True)\n",
    "# #         self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "# #     def forward(self, x):  # x: [batch, 3, 79]\n",
    "# #         attn_out, _ = self.attn(x, x, x)       # [batch, 3, 79]\n",
    "# #         x_avg = attn_out.mean(dim=1)           # [batch, 79]\n",
    "# #         return self.fc(x_avg)                  # [batch, num_classes]\n",
    "\n",
    "# # class MetaLearnerFC(nn.Module):\n",
    "# #     def __init__(self, feature_dim=79, num_classes=2):\n",
    "# #         super(MetaLearnerFC, self).__init__()\n",
    "# #         # Define the fully connected layers\n",
    "# #         self.fc1 = nn.Linear(feature_dim * 3, 3)  # 3 models, each with 79 features\n",
    "# #         self.relu = nn.ReLU()\n",
    "# #         self.fc2 = nn.Linear(3, num_classes)\n",
    "\n",
    "# #     def forward(self, x):  # x: [batch, 3, 79]\n",
    "# #         x = x.view(x.size(0), -1)  # Flatten to [batch, 3*79]\n",
    "# #         x = self.fc1(x)            # [batch, 128]\n",
    "# #         x = self.relu(x)           # [batch, 128]\n",
    "# #         x = self.fc2(x)            # [batch, num_classes]\n",
    "# #         return x\n",
    "\n",
    "# # class WeightedSumModel(nn.Module):\n",
    "# #     def __init__(self, feature_dim=79, num_vectors=3):\n",
    "# #         super(WeightedSumModel, self).__init__()\n",
    "# #         mean = 0\n",
    "# #         std = 0  # You can adjust this spread as needed\n",
    "# #         self.raw_weights = nn.Parameter(torch.randn(num_vectors))\n",
    "\n",
    "# #     def forward(self, x):  # x: [batch, 3, 79]\n",
    "# #         w = self.raw_weights\n",
    "# #         w_min = w.min()\n",
    "# #         w_max = w.max()\n",
    "\n",
    "# #         norm_w = (w - w_min) / (w_max - w_min + 1e-8)\n",
    "# #         norm_w = norm_w / (norm_w.sum() + 1e-8)\n",
    "# #         norm_w = norm_w.view(1, -1, 1).to(x.device)  # Move to same device as x\n",
    "\n",
    "# #         out = (x * norm_w).sum(dim=1)\n",
    "# #         return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31d252",
   "metadata": {
    "papermill": {
     "duration": 0.005574,
     "end_time": "2025-05-26T13:25:52.326074",
     "exception": false,
     "start_time": "2025-05-26T13:25:52.320500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-----------------**label encoder for Linear classifier**--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0510d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:52.338577Z",
     "iopub.status.busy": "2025-05-26T13:25:52.338093Z",
     "iopub.status.idle": "2025-05-26T13:25:53.766169Z",
     "shell.execute_reply": "2025-05-26T13:25:53.765409Z"
    },
    "papermill": {
     "duration": 1.43549,
     "end_time": "2025-05-26T13:25:53.767268",
     "exception": false,
     "start_time": "2025-05-26T13:25:52.331778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/fathomnet-dataset/DataSet/DataSe...</td>\n",
       "      <td>Sebastolobus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/fathomnet-dataset/DataSet/DataSe...</td>\n",
       "      <td>Apostichopus leukothele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/fathomnet-dataset/DataSet/DataSe...</td>\n",
       "      <td>Scotoplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/fathomnet-dataset/DataSet/DataSe...</td>\n",
       "      <td>Keratoisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/fathomnet-dataset/DataSet/DataSe...</td>\n",
       "      <td>Keratoisis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                    label\n",
       "0  /kaggle/input/fathomnet-dataset/DataSet/DataSe...             Sebastolobus\n",
       "1  /kaggle/input/fathomnet-dataset/DataSet/DataSe...  Apostichopus leukothele\n",
       "2  /kaggle/input/fathomnet-dataset/DataSet/DataSe...              Scotoplanes\n",
       "3  /kaggle/input/fathomnet-dataset/DataSet/DataSe...               Keratoisis\n",
       "4  /kaggle/input/fathomnet-dataset/DataSet/DataSe...               Keratoisis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_annotations_df = pd.read_csv(\"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\")\n",
    "label_encoder = LabelEncoder().fit(train_annotations_df[\"label\"].dropna())\n",
    "train_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077aeb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:53.781526Z",
     "iopub.status.busy": "2025-05-26T13:25:53.780831Z",
     "iopub.status.idle": "2025-05-26T13:25:54.001540Z",
     "shell.execute_reply": "2025-05-26T13:25:54.000953Z"
    },
    "papermill": {
     "duration": 0.229177,
     "end_time": "2025-05-26T13:25:54.002907",
     "exception": false,
     "start_time": "2025-05-26T13:25:53.773730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# Read labels directly from CSV\n",
    "df = pd.read_csv(\"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\")\n",
    "labels = df[\"label\"].tolist()\n",
    "indices = list(range(len(df)))\n",
    "\n",
    "# Stratified 40% split\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.9, random_state=12345)\n",
    "split_idx, _ = next(splitter.split(indices, labels))\n",
    "\n",
    "# Create datasets\n",
    "dataset_lin = FathomNetDataset_indep(csv_path=\"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\", transform=test_transforms, is_test=False)\n",
    "dataset_other = FathomNetDataset_tkn(csv_path=\"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\", transformation=test_transforms, is_test=False)\n",
    "\n",
    "# Subset based on stratified split\n",
    "subset_lin = Subset(dataset_lin, split_idx)\n",
    "subset_other = Subset(dataset_other, split_idx)\n",
    "\n",
    "# Dataloaders\n",
    "test_loader_lin = DataLoader(subset_lin, batch_size=32, shuffle=False)\n",
    "test_loader_other = DataLoader(subset_other, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbeba95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.017053Z",
     "iopub.status.busy": "2025-05-26T13:25:54.016795Z",
     "iopub.status.idle": "2025-05-26T13:25:54.053053Z",
     "shell.execute_reply": "2025-05-26T13:25:54.052437Z"
    },
    "papermill": {
     "duration": 0.044896,
     "end_time": "2025-05-26T13:25:54.054356",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.009460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# Create datasets\n",
    "dataset_lin = FathomNetDataset_indep(csv_path=\"/kaggle/input/fathomnet-dataset/annotations_Test.csv\", label_encoder = label_encoder, transform=test_transforms, is_test=True)\n",
    "dataset_other = FathomNetDataset_tkn(csv_path=\"/kaggle/input/fathomnet-dataset/annotations_Test.csv\", transformation=test_transforms, is_test=True)\n",
    "\n",
    "# Dataloaders\n",
    "test_loader_lin = DataLoader(dataset_lin, batch_size=32, shuffle=False)\n",
    "test_loader_other = DataLoader(dataset_other, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e984f601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.067495Z",
     "iopub.status.busy": "2025-05-26T13:25:54.067266Z",
     "iopub.status.idle": "2025-05-26T13:25:54.070805Z",
     "shell.execute_reply": "2025-05-26T13:25:54.070242Z"
    },
    "papermill": {
     "duration": 0.011078,
     "end_time": "2025-05-26T13:25:54.071825",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.060747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# # Load CSV and labels for stratification\n",
    "# csv_path = \"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\"\n",
    "# full_data = pd.read_csv(csv_path)\n",
    "# labels = full_data[\"label\"].tolist()\n",
    "\n",
    "# # Stratified split\n",
    "# splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=2468)\n",
    "# train_idx, val_idx = next(splitter.split(full_data[\"path\"], labels))\n",
    "\n",
    "# # Create full datasets\n",
    "# dataset_lin_full = FathomNetDataset_indep(csv_path=csv_path, transform=test_transforms, is_test=False)\n",
    "# dataset_other_full = FathomNetDataset_tkn(csv_path=csv_path, transformation=test_transforms, is_test=False)\n",
    "\n",
    "# # Subset using stratified indices\n",
    "# train_dataset_lin = Subset(dataset_lin_full, train_idx)\n",
    "# val_dataset_lin = Subset(dataset_lin_full, val_idx)\n",
    "\n",
    "# train_dataset_other = Subset(dataset_other_full, train_idx)\n",
    "# val_dataset_other = Subset(dataset_other_full, val_idx)\n",
    "\n",
    "# # DataLoaders\n",
    "# train_loader_lin = DataLoader(train_dataset_lin, batch_size=32, shuffle=True)\n",
    "# val_loader_lin = DataLoader(val_dataset_lin, batch_size=32, shuffle=False)\n",
    "\n",
    "# train_loader_other = DataLoader(train_dataset_other, batch_size=32, shuffle=True)\n",
    "# val_loader_other = DataLoader(val_dataset_other, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a04fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.084538Z",
     "iopub.status.busy": "2025-05-26T13:25:54.084326Z",
     "iopub.status.idle": "2025-05-26T13:25:54.088937Z",
     "shell.execute_reply": "2025-05-26T13:25:54.088321Z"
    },
    "papermill": {
     "duration": 0.012143,
     "end_time": "2025-05-26T13:25:54.090005",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.077862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_onehot = {int(onehot[vec].argmax()) : str(vec) for vec in onehot.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5511e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.103144Z",
     "iopub.status.busy": "2025-05-26T13:25:54.102930Z",
     "iopub.status.idle": "2025-05-26T13:25:54.111310Z",
     "shell.execute_reply": "2025-05-26T13:25:54.110817Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016461,
     "end_time": "2025-05-26T13:25:54.112367",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.095906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import torchvision.models as models  # ensure models refers to torchvision.models\n",
    "\n",
    "# # --- Model loading ---\n",
    "# # def load_models(weight_paths, **model_kwargs):\n",
    "# #     \"\"\"\n",
    "# #     Instantiate and load three models from the given checkpoint paths.\n",
    "# #     \"\"\"\n",
    "# #     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "# #     model2 = FathomnetClassTree(**model_kwargs)\n",
    "# #     # For linear, number of output classes should match your dataset (e.g., 79)\n",
    "# #     model3 = FathomnetClass(num_classes=79)\n",
    "\n",
    "# #     for m, w in zip((model1, model2, model3), weight_paths):\n",
    "# #         ckpt = torch.load(w, map_location='cpu')\n",
    "# #         m.load_state_dict(ckpt['model_state_dict'])\n",
    "# #         m.eval()\n",
    "# #     return model1, model2, model3\n",
    "\n",
    "# def load_models(weight_paths, meta_weight_path='/kaggle/input/lstm_v1/pytorch/meta_classifier/1/Meta_Attention_1.pth', **model_kwargs):\n",
    "#     \"\"\"\n",
    "#     Instantiate and load three base models and an optional meta-learner model.\n",
    "#     \"\"\"\n",
    "#     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "#     model2 = FathomnetClassTree(**model_kwargs)\n",
    "#     model3 = FathomnetClass(num_classes=79)  # Linear model\n",
    "\n",
    "#     for m, w in zip((model1, model2, model3), weight_paths):\n",
    "#         ckpt = torch.load(w, map_location='cpu', )\n",
    "#         m.load_state_dict(ckpt['model_state_dict'])\n",
    "#         m.eval()\n",
    "\n",
    "#     if meta_weight_path:\n",
    "#         meta_model = MetaLearnerAttention(num_classes=79)\n",
    "#         ckpt = torch.load(meta_weight_path, map_location='cpu')\n",
    "#         meta_model.load_state_dict(ckpt['model_state_dict'])\n",
    "#         meta_model.eval()\n",
    "#         return [model1, model2, model3, meta_model]\n",
    "\n",
    "#     return [model1, model2, model3]\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# # def ensemble_predict(ensemble_models, seq_images, lin_images,\n",
    "# #                      onehot, label_encoder, labels_idx):\n",
    "# #     \"\"\"\n",
    "# #     Predict by ensembling two sequence models and one linear model.\n",
    "# #     \"\"\"\n",
    "# #     # Sequence-based logits\n",
    "# #     logits1 = ensemble_models[0](seq_images)  # [B, T, V]\n",
    "# #     logits2 = ensemble_models[1](seq_images)\n",
    "# #     logits3 = ensemble_models[2](lin_images)  # [B, C]\n",
    "# #     seq_logits = (4.2 * logits1 + 5.8 * logits2) / 10\n",
    "# #     print(seq_logits.shape)\n",
    "# #     seq_preds = seq_logits.argmax(dim=-1)    # [B, T]            \n",
    "\n",
    "# #     # Decode sequence to single token per sample\n",
    "# #     final_tokens = []\n",
    "# #     for seq in seq_preds.tolist():\n",
    "# #         cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "# #         prefix = seq[:cutoff]\n",
    "# #         last_valid = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "# #         final_tokens.append(last_valid)\n",
    "# #     # Map tokens back to labels and one-hot encode for linear model\n",
    "# #     final_labels = [label_encoder.transform([new_onehot[idx]])[0] for idx in final_tokens]\n",
    "# #     # Linear model logits\n",
    "# #     num_classes = logits3.size(1)\n",
    "# #     onehot_dict = {i: torch.nn.functional.one_hot(torch.tensor(i % 79), num_classes).float() for i in range(151)}\n",
    "# #     one_hot_seq = torch.stack([onehot_dict[i] for i in final_labels]).float().to(logits3.device)\n",
    "# #     normalized_logits3 = (logits3 - logits3.min(dim=-1, keepdim=True).values) / (logits3.max(dim=-1, keepdim=True).values - logits3.min(dim=-1, keepdim=True).values)\n",
    "# #     print(logits3.shape)\n",
    "# #     # Average logits\n",
    "# #     final_logits = normalized_logits3 + 0.5 * one_hot_seq\n",
    "# #     predicted_classes = final_logits.argmax(dim=-1).tolist()\n",
    "# #     return label_encoder.inverse_transform(predicted_classes).tolist()\n",
    "\n",
    "\n",
    "# # def ensemble_predict(ensemble_models, seq_images, lin_images,\n",
    "# #                      onehot, label_encoder, labels_idx):\n",
    "# #     \"\"\"\n",
    "# #     Predict by ensembling two sequence models and one linear model.\n",
    "# #     \"\"\"\n",
    "# #     # --- Sequence-based logits: [B, T, V] each\n",
    "# #     logits1 = ensemble_models[0](seq_images)\n",
    "# #     logits2 = ensemble_models[1](seq_images)\n",
    "# #     seq_logits = (5.2 * logits1 + 4.8 * logits2) / 10  # [B, T, V]\n",
    "\n",
    "# #     # --- For each class, take the max over time → [B, V]\n",
    "# #     seq_max_logits = seq_logits.max(dim=1).values  # collapse T→classes\n",
    "\n",
    "# #     # --- Reduce to only those classes in labels_idx → [B, len(labels_idx)=79]\n",
    "# #     new_seq_logits = seq_max_logits[:, labels_idx]  # now matches linear-model output dims\n",
    "\n",
    "# #     # --- Your original linear logits and normalization\n",
    "# #     logits3 = ensemble_models[2](lin_images)        # [B, 79] after you train it\n",
    "# #     normalized_logits3 = (logits3 - logits3.min(dim=-1, keepdim=True).values) / (logits3.max(dim=-1, keepdim=True).values - logits3.min(dim=-1, keepdim=True).values + 1e-8)\n",
    "# #     new_seq_logits = (new_seq_logits - new_seq_logits.min(dim=-1, keepdim=True).values) / (new_seq_logits.max(dim=-1, keepdim=True).values - new_seq_logits.min(dim=-1, keepdim=True).values + 1e-8)\n",
    "\n",
    "# #     # --- Combine\n",
    "# #     print(normalized_logits3)\n",
    "# #     print(new_seq_logits)\n",
    "# #     final_logits = 0.27 * normalized_logits3 + 0.73 * new_seq_logits.to(logits3.device)\n",
    "# #     preds_idx    = final_logits.argmax(dim=-1).tolist()\n",
    "# #     return label_encoder.inverse_transform(preds_idx).tolist()\n",
    "\n",
    "\n",
    "# def ensemble_predict(ensemble_models, seq_images, lin_images,\n",
    "#                      onehot, label_encoder, labels_idx):\n",
    "#     \"\"\"\n",
    "#     Predict using 2 sequence models, 1 linear model, and a meta-learner.\n",
    "#     \"\"\"\n",
    "#     # --- Sequence-based logits: [B, T, V]\n",
    "#     logits1 = ensemble_models[0](seq_images)\n",
    "#     logits2 = ensemble_models[1](seq_images)\n",
    "#     seq_logits = (5.2 * logits1 + 4.8 * logits2) / 10  # [B, T, V]\n",
    "\n",
    "#     logits1_argmax = logits1.argmax(dim=-1)\n",
    "#     logits2_argmax = logits2.argmax(dim=-1)\n",
    "\n",
    "#     final_tokens1 = []\n",
    "#     final_tokens2 = []\n",
    "#     for seq in logits1_argmax.tolist():\n",
    "#         cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "#         prefix = seq[:cutoff]\n",
    "#         last_valid = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "#         final_tokens1.append(onehot[new_onehot[last_valid]])\n",
    "#     for seq in logits2_argmax.tolist():\n",
    "#         cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "#         prefix = seq[:cutoff]\n",
    "#         last_valid = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "#         final_tokens2.append(onehotpnew_onehot[last_valid]])\n",
    "\n",
    "#     final_tokens1 = torch.tensor(final_tokens1)\n",
    "#     print(final_tokens1)\n",
    "#     final_tokens2 = torch.tensor(final_tokens2)\n",
    "#     logits1 = final_tokens1[:, :, labels_idx]\n",
    "#     logits2 = final_tokens2[:, :, labels_idx]\n",
    "\n",
    "#     # --- Collapse time dim by max over T: [B, V]\n",
    "#     seq_max_logits = seq_logits.max(dim=1).values\n",
    "\n",
    "#     # --- Reduce to [B, 79] using only selected indices\n",
    "#     seq_selected = seq_max_logits[:, labels_idx]\n",
    "\n",
    "#     # --- Linear model logits\n",
    "#     logits3 = ensemble_models[2](lin_images)\n",
    "\n",
    "#     # Normalize both to [0, 1]\n",
    "#     def normalize(x):\n",
    "#         return (x - x.min(dim=-1, keepdim=True).values) / (x.max(dim=-1, keepdim=True).values - x.min(dim=-1, keepdim=True).values + 1e-8)\n",
    "\n",
    "#     # seq_selected = normalize(seq_selected)\n",
    "#     # logits3 = normalize(logits3)\n",
    "\n",
    "#     # --- Add dummy third vector (or replace if you have a 3rd)\n",
    "#     dummy_tree_logits = torch.zeros_like(logits3)  # Replace with actual 3rd model if needed\n",
    "\n",
    "#     # --- Stack for meta-learner\n",
    "#     x_meta = torch.stack([logits3, logits1, logits2], dim=1)  # [B, 3, 79]\n",
    "\n",
    "#     # --- Predict\n",
    "#     final_logits = ensemble_models[3](x_meta.to(logits3.device))\n",
    "#     preds_idx = final_logits.argmax(dim=-1).tolist()\n",
    "#     return label_encoder.inverse_transform(preds_idx).tolist()\n",
    "\n",
    "\n",
    "\n",
    "# # --- Setup ---\n",
    "# # Determine special token indices\n",
    "# stop_tkn_idx = torch.argmax(torch.tensor(\n",
    "#     onehot.get('spl_stp', torch.zeros_like(torch.tensor(onehot['-']))))\n",
    "# ).item()\n",
    "# pad_tkn_idx = torch.argmax(torch.tensor(\n",
    "#     onehot.get('-', torch.zeros_like(torch.tensor(onehot['-']))))\n",
    "# ).item()\n",
    "\n",
    "# model_kwargs = {\n",
    "#     'input_dim': 1280,\n",
    "#     'hidden_size': 512,\n",
    "#     'vocab_size': 151,\n",
    "#     'stop_tkn_idx': stop_tkn_idx,\n",
    "#     'pad_tkn_idx': pad_tkn_idx,\n",
    "#     'max_len': 7,\n",
    "# }\n",
    "# # Paths to saved checkpoints\n",
    "# weight_paths = ['/kaggle/input/lstm_v1/pytorch/v1/5/LSTM_3k_4.pth', \n",
    "#                 '/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/5/TreeLSTM_Nary_512_7ok.pth',\n",
    "#                 '/kaggle/input/lstm_v1/pytorch/linear/1/Linear_3.pth']\n",
    "\n",
    "# # Load and move to device\n",
    "# ensemble_models = load_models(weight_paths, **model_kwargs)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for m in ensemble_models:\n",
    "#     m.to(device)\n",
    "\n",
    "# # --- Inference using separate loaders ---\n",
    "# predictions, ids = [], []\n",
    "# for (imgs_seq, paths_seq), (imgs_lin, paths_lin) in tqdm(\n",
    "#         zip(test_loader_other, test_loader_lin),\n",
    "#         desc=\"Processing batches\"\n",
    "# ):\n",
    "#     # Ensure both loaders yield the same ordering\n",
    "#     assert paths_seq == paths_lin, \\\n",
    "#         \"Mismatched batch ordering between sequence and linear loaders\"\n",
    "\n",
    "#     imgs_seq = imgs_seq.to(device)\n",
    "#     imgs_lin = imgs_lin.to(device)\n",
    "\n",
    "#     preds = ensemble_predict(\n",
    "#         ensemble_models,\n",
    "#         imgs_seq,\n",
    "#         imgs_lin,\n",
    "#         onehot,\n",
    "#         label_encoder,\n",
    "#         labels_idx\n",
    "#     )\n",
    "#     predictions.extend(preds)\n",
    "#     # Extract numeric ID from filename pattern\n",
    "#     ids.extend([\n",
    "#         int(p.split('/')[-1].split('_')[1].split('.')[0])\n",
    "#         for p in paths_seq\n",
    "#     ])\n",
    "\n",
    "# print(f\"Total samples: {len(ids)}\")\n",
    "# print(f\"First ID: {ids[0]}, First prediction: {predictions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1fc377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.125895Z",
     "iopub.status.busy": "2025-05-26T13:25:54.125663Z",
     "iopub.status.idle": "2025-05-26T13:25:54.130490Z",
     "shell.execute_reply": "2025-05-26T13:25:54.130007Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012681,
     "end_time": "2025-05-26T13:25:54.131469",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.118788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import torchvision.models as models  # ensure models refers to torchvision.models\n",
    "# import pandas as pd\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# # --- Model loading ---\n",
    "# def load_models(weight_paths,\n",
    "#                 meta_weight_path='/kaggle/input/lstm_v1/pytorch/meta_classifier/10/WeightedSumModel_new_2.pth',\n",
    "#                 **model_kwargs):\n",
    "#     \"\"\"\n",
    "#     Instantiate and load three base models and an optional meta-learner model.\n",
    "#     \"\"\"\n",
    "#     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "#     model2 = FathomnetClassTree(**model_kwargs)\n",
    "#     model3 = FathomnetClass(num_classes=79)\n",
    "\n",
    "#     for m, w in zip((model1, model2, model3), weight_paths):\n",
    "#         ckpt = torch.load(w, map_location='cpu')\n",
    "#         m.load_state_dict(ckpt['model_state_dict'])\n",
    "#         m.eval()\n",
    "\n",
    "#     if meta_weight_path:\n",
    "#         meta_model = WeightedSumModel()\n",
    "#         ckpt = torch.load(meta_weight_path, map_location='cpu')\n",
    "#         meta_model.load_state_dict(ckpt['model_state_dict'])\n",
    "#         meta_model.eval()\n",
    "#         return [model1, model2, model3, meta_model]\n",
    "\n",
    "#     return [model1, model2, model3]\n",
    "\n",
    "# # --- Prediction function ---\n",
    "# @torch.no_grad()\n",
    "# def ensemble_predict(ensemble_models, seq_images, lin_images,\n",
    "#                      onehot, label_encoder, labels_idx):\n",
    "#     \"\"\"\n",
    "#     Predict using 2 sequence models, 1 linear model, and a meta-learner.\n",
    "#     \"\"\"\n",
    "#     logits1 = ensemble_models[0](seq_images)    # LSTM\n",
    "#     logits2 = ensemble_models[1](seq_images)    # Tree\n",
    "\n",
    "#     arg1 = logits1.argmax(dim=-1).tolist()\n",
    "#     arg2 = logits2.argmax(dim=-1).tolist()\n",
    "\n",
    "#     final1, final2 = [], []\n",
    "#     for seq in arg1:\n",
    "#         cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "#         prefix = seq[:cutoff]\n",
    "#         last = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "#         final1.append(onehot[new_onehot[last]])\n",
    "#     for seq in arg2:\n",
    "#         cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "#         prefix = seq[:cutoff]\n",
    "#         last = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "#         final2.append(onehot[new_onehot[last]])\n",
    "\n",
    "#     logits3 = ensemble_models[2](lin_images)\n",
    "#     logits3 = F.normalize(logits3, dim=-1)\n",
    "    \n",
    "#     tensor_final1 = torch.tensor(final1, device=logits3.device, dtype=logits3.dtype)\n",
    "#     tensor_final1 = tensor_final1[:, labels_idx]\n",
    "#     tensor_final1 = F.normalize(tensor_final1, dim=-1)\n",
    "    \n",
    "#     tensor_final2 = torch.tensor(final2, device=logits3.device, dtype=logits3.dtype)\n",
    "#     tensor_final2 = tensor_final2[:, labels_idx]\n",
    "#     tensor_final2 = F.normalize(tensor_final2, dim=-1)\n",
    "\n",
    "#     stacked = torch.stack([logits3, tensor_final1, tensor_final2], dim=1)  # [batch, 3, dim]\n",
    "#     final_logits = ensemble_models[3](stacked)  # WeightedSumModel\n",
    "    \n",
    "#     # final_logits = (3.2 * tensor_final1 + 3.5 * tensor_final2 + 2.7 * logits3) / 9.6\n",
    "#     preds_idx = final_logits.argmax(dim=-1).tolist()\n",
    "#     return label_encoder.inverse_transform(preds_idx).tolist()\n",
    "\n",
    "# # --- Setup ---\n",
    "# stop_tkn_idx = torch.argmax(torch.tensor(\n",
    "#     onehot.get('spl_stp', torch.zeros_like(torch.tensor(onehot['-'])))\n",
    "# )).item()\n",
    "# pad_tkn_idx = torch.argmax(torch.tensor(\n",
    "#     onehot.get('-', torch.zeros_like(torch.tensor(onehot['-'])))\n",
    "# )).item()\n",
    "\n",
    "# model_kwargs = {\n",
    "#     'input_dim': 1280,\n",
    "#     'hidden_size': 512,\n",
    "#     'vocab_size': 151,\n",
    "#     'stop_tkn_idx': stop_tkn_idx,\n",
    "#     'pad_tkn_idx': pad_tkn_idx,\n",
    "#     'max_len': 7,\n",
    "# }\n",
    "\n",
    "# weight_paths = [\n",
    "#     '/kaggle/input/lstm_v1/pytorch/v1/6/LSTM_ens_3p.pth',\n",
    "#     '/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/6/TreeLSTM_Nary_ens_3p.pth',\n",
    "#     '/kaggle/input/lstm_v1/pytorch/linear/4/Linear_ens_3.pth'\n",
    "# ]\n",
    "\n",
    "# ensemble_models = load_models(weight_paths, **model_kwargs)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for m in ensemble_models:\n",
    "#     m.to(device)\n",
    "\n",
    "# # --- Inference toggle ---\n",
    "# include_paths_in_output = False  # Set to False to exclude file path column\n",
    "\n",
    "# # --- Inference ---\n",
    "# predictions, ids = [], []\n",
    "# paths_out = [] if include_paths_in_output else None\n",
    "\n",
    "# for (imgs_seq, paths_seq), (imgs_lin, paths_lin) in tqdm(\n",
    "#         zip(test_loader_other, test_loader_lin),\n",
    "#         desc=\"Processing batches\"\n",
    "# ):\n",
    "#     assert paths_seq == paths_lin, \"Batch ordering mismatch\"\n",
    "#     imgs_seq, imgs_lin = imgs_seq.to(device), imgs_lin.to(device)\n",
    "\n",
    "#     preds = ensemble_predict(\n",
    "#         ensemble_models,\n",
    "#         imgs_seq,\n",
    "#         imgs_lin,\n",
    "#         onehot,\n",
    "#         label_encoder,\n",
    "#         labels_idx\n",
    "#     )\n",
    "#     predictions.extend(preds)\n",
    "#     # ids.extend(paths_seq)\n",
    "#     ids.extend(int(p.split('_')[-1].split('.')[0]) for p in paths_seq)\n",
    "    \n",
    "#     if include_paths_in_output:\n",
    "#         paths_out.extend(paths_seq)\n",
    "\n",
    "# print(f\"Total samples: {len(ids)}\")\n",
    "# print(f\"First ID: {ids[0]}, First prediction: {predictions[0]}\")\n",
    "\n",
    "# # --- Create submission DataFrame ---\n",
    "# data = {'id': ids, 'prediction': predictions}\n",
    "# if include_paths_in_output:\n",
    "#     data['path'] = paths_out\n",
    "\n",
    "# submission_df = pd.DataFrame(data)\n",
    "# print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b414da",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-26T13:25:54.144825Z",
     "iopub.status.busy": "2025-05-26T13:25:54.144589Z",
     "iopub.status.idle": "2025-05-26T13:29:40.251134Z",
     "shell.execute_reply": "2025-05-26T13:29:40.250291Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 226.114612,
     "end_time": "2025-05-26T13:29:40.252322",
     "exception": false,
     "start_time": "2025-05-26T13:25:54.137710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_m-dc08266a.pth\n",
      "100%|██████████| 208M/208M [00:01<00:00, 192MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51e048a3006488eac5c48568f2aec0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e89649d09434ca1ad39f3024264b0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/788M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/963655924.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(w, map_location='cpu')\n",
      "Processing batches: 25it [02:53,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 788\n",
      "First ID: 1, First prediction: Pandalus amplus\n",
      "   id       prediction\n",
      "0   1  Pandalus amplus\n",
      "1   2       Funiculina\n",
      "2   3       Funiculina\n",
      "3   4       Funiculina\n",
      "4   5       Funiculina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "# --- Model loading ---\n",
    "def load_models(weight_paths,\n",
    "                meta_weight_path=None,\n",
    "                device='cpu',\n",
    "                **model_kwargs):\n",
    "    model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "    model2 = FathomnetClassTree(**model_kwargs)\n",
    "    model3 = FathomnetClass(num_classes=79)\n",
    "    model4 = FathomnetClassResnet(input_dim=2048, hidden_size=512, vocab_size=151,\n",
    "                                 stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "                                 pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(), max_len=7)\n",
    "    model5 = FathomnetClassSwin(input_dim=1536, hidden_size=512, vocab_size=151,\n",
    "                                 stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "                                 pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(), max_len=7)\n",
    "\n",
    "    for m, w in zip((model1, model2, model3, model4), weight_paths):\n",
    "        ckpt = torch.load(w, map_location='cpu')\n",
    "        m.load_state_dict(ckpt['model_state_dict'])\n",
    "        m.eval()\n",
    "        m.to(device)  # Move model to device here AFTER loading and eval\n",
    "\n",
    "    if meta_weight_path:\n",
    "        meta_model = MetaLearnerTokenWise()\n",
    "        ckpt = torch.load(meta_weight_path, map_location='cpu')\n",
    "        meta_model.load_state_dict(ckpt['model_state_dict'])\n",
    "        meta_model.eval()\n",
    "        meta_model.to(device)  # Move meta_model to device\n",
    "        return [model1, model2, model3, model4, model5, meta_model]\n",
    "\n",
    "    return [model1, model2, model3, model4, model5]\n",
    "\n",
    "@torch.no_grad()\n",
    "def ensemble_predict(ensemble_models, seq_images, lin_images,\n",
    "                     onehot, label_encoder, labels_idx, w = [0.35, 0.25, 0.16, 0.25, 0.13]):\n",
    "    onehot_argmax = {v.values.argmax(): k for k, v in onehot.items()}\n",
    "    new_argmax = {new_idx: onehot_argmax[orig_idx] for new_idx, orig_idx in enumerate(labels_idx)}\n",
    "    \n",
    "    def predict_single(seq_img, lin_img):\n",
    "        logits1 = ensemble_models[0](seq_img)  # [1, 7, 151]\n",
    "        logits2 = ensemble_models[1](seq_img)  # [1, 7, 151]\n",
    "        logits3 = ensemble_models[2](seq_img)\n",
    "        logits4 = ensemble_models[3](seq_img)  # [1, 7, 151]\n",
    "        logits5 = ensemble_models[4](seq_img)  # [1, 7, 151]\n",
    "\n",
    "        def get_k(logits):\n",
    "            pc = logits[0].argmax(dim=1).tolist()\n",
    "            cutoff = next((i+1 for i in reversed(range(len(pc))) if pc[i] not in (5,6)), len(pc))\n",
    "            prefix = pc[:cutoff]\n",
    "            return next((pos for pos in reversed(range(cutoff)) if prefix[pos] in labels_idx), 0)\n",
    "\n",
    "        k1, k2, k4, k5 = get_k(logits1), get_k(logits2), get_k(logits4), get_k(logits5)\n",
    "\n",
    "        # f1 = logits1[0, k1, labels_idx]\n",
    "        # f2 = logits2[0, k2, labels_idx]\n",
    "        # f3 = logits3\n",
    "        # f4 = logits4[0, k4, labels_idx]\n",
    "        # f5 = logits5[0, k5, labels_idx]\n",
    "\n",
    "        f1 = (logits1[0, k1, labels_idx] - logits1[0, k1, labels_idx].mean()) / (logits1[0, k1, labels_idx].std() + 1e-6)\n",
    "        f2 = (logits2[0, k2, labels_idx] - logits2[0, k2, labels_idx].mean()) / (logits2[0, k2, labels_idx].std() + 1e-6)\n",
    "        f3 = (logits3 - logits3.mean()) / (logits3.std() + 1e-6)\n",
    "        f4 = (logits4[0, k4, labels_idx] - logits4[0, k4, labels_idx].mean()) / (logits4[0, k4, labels_idx].std() + 1e-6)\n",
    "        f5 = (logits5[0, k5, labels_idx] - logits5[0, k5, labels_idx].mean()) / (logits5[0, k5, labels_idx].std() + 1e-6)\n",
    "\n",
    "        # f_logits = torch.stack([f2, f4, f1], dim=0).unsqueeze(0)  # [1, 3, 79]\n",
    "        # final_logits = ensemble_models[4](f_logits)  # [1, 79]\n",
    "\n",
    "        final_logits = w[0] * f1 + w[1] * f2 + w[2] * f3 + w[3] * f4 + w[4] * f5\n",
    "\n",
    "        idx = final_logits.argmax(dim=-1).item()\n",
    "\n",
    "        return new_argmax.get(idx, None)\n",
    "\n",
    "    batch_size = seq_images.size(0)\n",
    "    preds = []\n",
    "    for i in range(batch_size):\n",
    "        si = seq_images[i:i+1]\n",
    "        li = lin_images[i:i+1]\n",
    "        preds.append(predict_single(si, li))\n",
    "    return preds\n",
    "\n",
    "\n",
    "# --- Setup ---\n",
    "stop_tkn_idx = torch.argmax(torch.tensor(\n",
    "    onehot.get('spl_stp', torch.zeros_like(torch.tensor(onehot['-'])))\n",
    ")).item()\n",
    "pad_tkn_idx = torch.argmax(torch.tensor(\n",
    "    onehot.get('-', torch.zeros_like(torch.tensor(onehot['-'])))\n",
    ")).item()\n",
    "\n",
    "model_kwargs = {\n",
    "    'input_dim': 1280,\n",
    "    'hidden_size': 512,\n",
    "    'vocab_size': 151,\n",
    "    'stop_tkn_idx': stop_tkn_idx,\n",
    "    'pad_tkn_idx': pad_tkn_idx,\n",
    "    'max_len': 7,\n",
    "}\n",
    "# weight_paths = [\n",
    "#     '/kaggle/input/retrained-models/effi_lstm/effi_lstm_ens_8o',\n",
    "#     '/kaggle/input/retrained-models/effi_tree/effi_treelstm_ens_5o',\n",
    "#     '/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth',\n",
    "#     '/kaggle/input/retrained-models/resnest/resnest_treelstm_ens_5o'\n",
    "# ]\n",
    "\n",
    "weight_paths = [\n",
    "    '/kaggle/input/lstm_v1/pytorch/v1/6/LSTM_3k_4.pth',\n",
    "    '/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/6/TreeLSTM_Nary_512_7ok.pth',\n",
    "    '/kaggle/input/lstm_v1/pytorch/linear/4/Linear_3.pth',\n",
    "    '/kaggle/input/retrained-models/resnest/resnest_treelstm_ens_5o',\n",
    "    '/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth'\n",
    "]\n",
    "\n",
    "ensemble_models = load_models(weight_paths, **model_kwargs)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for m in ensemble_models:\n",
    "    m.to(device)\n",
    "\n",
    "# --- Inference toggle ---\n",
    "include_paths_in_output = False\n",
    "\n",
    "# --- Inference ---\n",
    "predictions = []\n",
    "ids = []\n",
    "paths_out = [] if include_paths_in_output else None\n",
    "\n",
    "for (imgs_seq, paths_seq), (imgs_lin, paths_lin) in tqdm(\n",
    "        zip(test_loader_other, test_loader_lin),\n",
    "        desc=\"Processing batches\"\n",
    "):\n",
    "    assert paths_seq == paths_lin, \"Batch ordering mismatch\"\n",
    "    imgs_seq, imgs_lin = imgs_seq.to(device), imgs_lin.to(device)\n",
    "\n",
    "    batch_preds = ensemble_predict(\n",
    "        ensemble_models,\n",
    "        imgs_seq,\n",
    "        imgs_lin,\n",
    "        onehot,\n",
    "        label_encoder,\n",
    "        labels_idx\n",
    "    )\n",
    "    predictions.extend(batch_preds)\n",
    "    ids.extend(int(p.split('_')[-1].split('.')[0]) for p in paths_seq)\n",
    "\n",
    "    if include_paths_in_output:\n",
    "        paths_out.extend(paths_seq)\n",
    "\n",
    "print(f\"Total samples: {len(ids)}\")\n",
    "print(f\"First ID: {ids[0]}, First prediction: {predictions[0]}\")\n",
    "\n",
    "# --- Create submission DataFrame ---\n",
    "data = {\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "}\n",
    "if include_paths_in_output:\n",
    "    data['path'] = paths_out\n",
    "\n",
    "# Sanity check and truncate any mismatched lengths\n",
    "lengths = {k: len(v) for k, v in data.items()}\n",
    "min_len = min(lengths.values())\n",
    "for k in data:\n",
    "    data[k] = data[k][:min_len]\n",
    "\n",
    "submission_df = pd.DataFrame(data)\n",
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2422a558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.270611Z",
     "iopub.status.busy": "2025-05-26T13:29:40.270381Z",
     "iopub.status.idle": "2025-05-26T13:29:40.275078Z",
     "shell.execute_reply": "2025-05-26T13:29:40.274524Z"
    },
    "papermill": {
     "duration": 0.01488,
     "end_time": "2025-05-26T13:29:40.276153",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.261273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# from collections import Counter\n",
    "# # Assuming FathomnetClassLSTM, FathomnetClassTree, FathomnetClass, FathomnetClassResnet,\n",
    "# # FathomnetClassSwin and onehot, labels_idx, test_loader_other, test_loader_lin are defined elsewhere\n",
    "\n",
    "# # --- Model loading ---\n",
    "# def load_models(weight_paths, device='cpu', **model_kwargs):\n",
    "#     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "#     model2 = FathomnetClassTree(**model_kwargs)\n",
    "#     model3 = FathomnetClass(num_classes=79)\n",
    "#     model4 = FathomnetClassResnet(\n",
    "#         input_dim=2048,\n",
    "#         hidden_size=model_kwargs.get('hidden_size', 512),\n",
    "#         vocab_size=model_kwargs['vocab_size'],\n",
    "#         stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#         pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(),\n",
    "#         max_len=model_kwargs['max_len']\n",
    "#     )\n",
    "#     model5 = FathomnetClassSwin(\n",
    "#         input_dim=1536,\n",
    "#         hidden_size=model_kwargs.get('hidden_size', 512),\n",
    "#         vocab_size=model_kwargs['vocab_size'],\n",
    "#         stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#         pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(),\n",
    "#         max_len=model_kwargs['max_len']\n",
    "#     )\n",
    "\n",
    "#     for m, w in zip((model1, model2, model3, model4, model5), weight_paths):\n",
    "#         ckpt = torch.load(w, map_location='cpu')\n",
    "#         m.load_state_dict(ckpt['model_state_dict'])\n",
    "#         m.eval()\n",
    "#         m.to(device)\n",
    "\n",
    "#     return [model1, model2, model3, model4, model5]\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def ensemble_predict(ensemble_models, seq_images, lin_images, onehot, labels_idx):\n",
    "#     onehot_argmax = {v.values.argmax(): k for k, v in onehot.items()}\n",
    "#     new_argmax = {new_idx: onehot_argmax[orig_idx] for new_idx, orig_idx in enumerate(labels_idx)}\n",
    "\n",
    "#     def get_pred(logits, use_seq=True):\n",
    "#         if use_seq:\n",
    "#             pc = logits[0].argmax(dim=1).tolist()\n",
    "#             cutoff = next((i+1 for i in reversed(range(len(pc))) if pc[i] not in (5, 6)), len(pc))\n",
    "#             prefix = pc[:cutoff]\n",
    "#             k = next((pos for pos in reversed(range(cutoff)) if prefix[pos] in labels_idx), 0)\n",
    "#             vals = logits[0, k, labels_idx]\n",
    "#         else:\n",
    "#             vals = logits[0]\n",
    "#         idx = vals.argmax().item()\n",
    "#         return new_argmax.get(idx, None)\n",
    "\n",
    "#     preds = []\n",
    "#     for si, li in zip(seq_images, lin_images):\n",
    "#         si, li = si.unsqueeze(0), li.unsqueeze(0)\n",
    "#         # get logits from each model\n",
    "#         logits1 = ensemble_models[0](si)\n",
    "#         logits2 = ensemble_models[1](si)\n",
    "#         logits3 = ensemble_models[2](li)\n",
    "#         logits4 = ensemble_models[3](si)\n",
    "#         logits5 = ensemble_models[4](si)\n",
    "        \n",
    "#         # individual model predictions\n",
    "#         p1 = get_pred(logits1, use_seq=True)\n",
    "#         p2 = get_pred(logits2, use_seq=True)\n",
    "#         p3 = get_pred(logits3, use_seq=False)\n",
    "#         p4 = get_pred(logits4, use_seq=True)\n",
    "#         p5 = get_pred(logits5, use_seq=True)\n",
    "        \n",
    "#         # majority voting\n",
    "#         votes = [p1, p2, p3, p4, p5]\n",
    "#         weights = [5.5, 4.5, 1, 4, 1.5]\n",
    "#         vote_scores = {}\n",
    "#         for pred, weight in zip(votes, weights):\n",
    "#             vote_scores[pred] = vote_scores.get(pred, 0) + weight\n",
    "#         final_pred = max(vote_scores.items(), key=lambda x: x[1])[0]\n",
    "#         preds.append(final_pred)\n",
    "#     return preds\n",
    "\n",
    "# # --- Setup ---\n",
    "# stop_tkn_idx = torch.argmax(torch.tensor(onehot['spl_stp'])).item()\n",
    "# pad_tkn_idx = torch.argmax(torch.tensor(onehot['-'])).item()\n",
    "# model_kwargs = {'input_dim': 1280, 'hidden_size': 512, 'vocab_size': 151, 'stop_tkn_idx': stop_tkn_idx, 'pad_tkn_idx': pad_tkn_idx, 'max_len': 7}\n",
    "# weight_paths = [\n",
    "#     '/kaggle/input/retrained-models/effi_lstm/effi_lstm_ens_8o',\n",
    "#     '/kaggle/input/retrained-models/effi_tree/effi_treelstm_ens_5o',\n",
    "#     '/kaggle/input/retrained-models/effi_lin_64/effi_ens_2o_complete',\n",
    "#     '/kaggle/input/retrained-models/resnest/resnest_treelstm_ens_5o',\n",
    "#     '/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth'\n",
    "# ]\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# ensemble_models = load_models(weight_paths, device=device, **model_kwargs)\n",
    "\n",
    "# # --- Inference ---\n",
    "# predictions, ids = [], []\n",
    "# for (imgs_seq, paths_seq), (imgs_lin, paths_lin) in tqdm(zip(test_loader_other, test_loader_lin), desc=\"Processing batches\"):\n",
    "#     assert paths_seq == paths_lin, \"Batch ordering mismatch\"\n",
    "#     imgs_seq, imgs_lin = imgs_seq.to(device), imgs_lin.to(device)\n",
    "#     batch_preds = ensemble_predict(ensemble_models, imgs_seq, imgs_lin, onehot, labels_idx)\n",
    "#     predictions.extend(batch_preds)\n",
    "#     ids.extend([int(p.split('_')[-1].split('.')[0]) for p in paths_seq])\n",
    "\n",
    "# # prepare submission\n",
    "# submission_df = pd.DataFrame({'id': ids, 'prediction': predictions})\n",
    "# print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "835bbd03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.292957Z",
     "iopub.status.busy": "2025-05-26T13:29:40.292718Z",
     "iopub.status.idle": "2025-05-26T13:29:40.297252Z",
     "shell.execute_reply": "2025-05-26T13:29:40.296728Z"
    },
    "papermill": {
     "duration": 0.014222,
     "end_time": "2025-05-26T13:29:40.298295",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.284073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # --- 1. Load your ensemble models as before ---\n",
    "# def load_models(weight_paths,\n",
    "#                 meta_weight_path=None,\n",
    "#                 device='cpu',\n",
    "#                 **model_kwargs):\n",
    "#     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "#     model2 = FathomnetClassTree(**model_kwargs)\n",
    "#     model3 = FathomnetClassSwin(input_dim=1536, hidden_size=512, vocab_size=151,\n",
    "#                                    stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#                                    pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(), max_len=7)\n",
    "#     model4 = FathomnetClassResnet(input_dim=2048, hidden_size=512, vocab_size=151,\n",
    "#                                  stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#                                  pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(), max_len=7)\n",
    "\n",
    "#     for m, w in zip((model1, model2, model3, model4), weight_paths):\n",
    "#         ckpt = torch.load(w, map_location='cpu')\n",
    "#         m.load_state_dict(ckpt['model_state_dict'])\n",
    "#         m.eval()\n",
    "#         m.to(device)  # Move model to device here AFTER loading and eval\n",
    "\n",
    "#     if meta_weight_path:\n",
    "#         meta_model = MetaLearnerTokenWise()\n",
    "#         ckpt = torch.load(meta_weight_path, map_location='cpu')\n",
    "#         meta_model.load_state_dict(ckpt['model_state_dict'])\n",
    "#         meta_model.eval()\n",
    "#         meta_model.to(device)  # Move meta_model to device\n",
    "#         return [model1, model2, model3, model4, meta_model]\n",
    "\n",
    "#     return [model1, model2, model3, model4]\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def ensemble_predict_single(models, x, w, labels_idx):\n",
    "#     # Compute the three model logits and normalize per your logic:\n",
    "#     logits1 = models[0](x)  # [1,T,V]\n",
    "#     logits2 = models[1](x)\n",
    "#     logits3 = models[2](x)\n",
    "#     logits4 = models[3](x)\n",
    "\n",
    "#     def extract(logits):\n",
    "#         pc = logits[0].argmax(dim=1).tolist()\n",
    "#         cutoff = next((i+1 for i in reversed(range(len(pc))) if pc[i] not in (5,6)), len(pc))\n",
    "#         pos = next((i for i in reversed(range(cutoff)) if pc[i] in labels_idx), 0)\n",
    "#         vec = logits[0, pos, labels_idx]\n",
    "#         return (vec - vec.mean()) / (vec.std() + 1e-6)\n",
    "\n",
    "#     f1 = extract(logits1)\n",
    "#     f2 = extract(logits2)\n",
    "#     f3 = extract(logits3)\n",
    "#     f4 = extract(logits4)\n",
    "\n",
    "#     return f1, f3, f2, f4\n",
    "\n",
    "# # --- 2. Setup & load models ---\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model_kwargs = { 'input_dim':1280, 'hidden_size':512, 'vocab_size':151,\n",
    "#                  'stop_tkn_idx':torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#                  'pad_tkn_idx':torch.argmax(torch.tensor(onehot['-'])).item(),\n",
    "#                  'max_len':7 }\n",
    "\n",
    "# weight_paths = [\n",
    "#     '/kaggle/input/retrained-models/effi_lstm/effi_lstm_ens_8o',\n",
    "#     '/kaggle/input/retrained-models/effi_tree/effi_treelstm_ens_5o',\n",
    "#     '/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth',\n",
    "#     '/kaggle/input/retrained-models/resnest/resnest_treelstm_ens_5o'\n",
    "# ]\n",
    "# ensemble_models = load_models(weight_paths, **model_kwargs)\n",
    "# for m in ensemble_models:\n",
    "#     m.to(device)\n",
    "\n",
    "# # --- 3. Collect all normalized logits and true labels once ---\n",
    "# all_f1, all_f2, all_f3, all_f4 = [], [], [], []\n",
    "# true_labels_list = []\n",
    "\n",
    "# for (seq_imgs, seq_lbls), (lin_imgs, lin_lbls) in tqdm(\n",
    "#         zip(val_loader_other, val_loader_lin),\n",
    "#         total=len(val_loader_other),\n",
    "#         desc=\"Collecting logits\",\n",
    "#         dynamic_ncols=True\n",
    "# ):\n",
    "#     assert seq_lbls == lin_lbls, \"Mismatch in labels\"\n",
    "#     seq_imgs = seq_imgs.to(device)\n",
    "\n",
    "#     for i in range(seq_imgs.size(0)):\n",
    "#         x = seq_imgs[i:i+1]\n",
    "#         f1, f3, f2, f4 = ensemble_predict_single(\n",
    "#             ensemble_models, x, None, labels_idx\n",
    "#         )\n",
    "#         all_f1.append(f1)           # LSTM (normalized)\n",
    "#         all_f2.append(f2) # Linear (raw logits)\n",
    "#         all_f3.append(f3)           # TreeLSTM (normalized)\n",
    "#         all_f4.append(f4)           # ResNet (normalized)\n",
    "#         true_labels_list.append(lin_lbls[i])  # raw string label\n",
    "\n",
    "# # Stack into tensors of shape [N, num_classes]\n",
    "# all_f1 = torch.stack(all_f1)  # LSTM\n",
    "# all_f2 = torch.stack(all_f2)  # Linear\n",
    "# all_f3 = torch.stack(all_f3)  # TreeLSTM\n",
    "# all_f4 = torch.stack(all_f4)  # ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02811dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.315001Z",
     "iopub.status.busy": "2025-05-26T13:29:40.314773Z",
     "iopub.status.idle": "2025-05-26T13:29:40.317708Z",
     "shell.execute_reply": "2025-05-26T13:29:40.317170Z"
    },
    "papermill": {
     "duration": 0.012693,
     "end_time": "2025-05-26T13:29:40.318877",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.306184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# save_path = 'logits.pth'\n",
    "\n",
    "# torch.save({\n",
    "#     'all_f1': all_f1,                  # LSTM features\n",
    "#     'all_f2': all_f2,                  # Linear logits\n",
    "#     'all_f3': all_f3,                  # TreeLSTM features\n",
    "#     'all_f4': all_f4,                  # ResNet features\n",
    "#     'true_labels_list': true_labels_list  # Raw string labels\n",
    "# }, save_path)\n",
    "\n",
    "# print(f\"✅ Saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387734bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.387526Z",
     "iopub.status.busy": "2025-05-26T13:29:40.387256Z",
     "iopub.status.idle": "2025-05-26T13:29:40.390234Z",
     "shell.execute_reply": "2025-05-26T13:29:40.389751Z"
    },
    "papermill": {
     "duration": 0.012817,
     "end_time": "2025-05-26T13:29:40.391255",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.378438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logits = torch.load('/kaggle/input/logits-50-2468/logits (1).pth')\n",
    "# all_f1 = logits['all_f1']\n",
    "# all_f2 = logits['all_f2']\n",
    "# all_f3 = logits['all_f3']\n",
    "# all_f4 = logits['all_f4']\n",
    "# true_labels_list = logits['true_labels_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3f1cb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.408117Z",
     "iopub.status.busy": "2025-05-26T13:29:40.407890Z",
     "iopub.status.idle": "2025-05-26T13:29:40.410970Z",
     "shell.execute_reply": "2025-05-26T13:29:40.410408Z"
    },
    "papermill": {
     "duration": 0.01258,
     "end_time": "2025-05-26T13:29:40.412002",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.399422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.cuda.empty_cache()             # Releases unused memory back to the GPU\n",
    "# torch.cuda.ipc_collect()            # Cleans up inter-process memory (if any)\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.reset_accumulated_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111193f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.429102Z",
     "iopub.status.busy": "2025-05-26T13:29:40.428845Z",
     "iopub.status.idle": "2025-05-26T13:29:40.432089Z",
     "shell.execute_reply": "2025-05-26T13:29:40.431375Z"
    },
    "papermill": {
     "duration": 0.013072,
     "end_time": "2025-05-26T13:29:40.433266",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.420194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = torch.load('/kaggle/working/logits.pth')\n",
    "# all_f1 = data['all_f1']\n",
    "# all_f2 = data['all_f2']\n",
    "# all_f3 = data['all_f3']\n",
    "# all_f4 = data['all_f4']\n",
    "# true_labels_list = data['true_labels_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e603bb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.450615Z",
     "iopub.status.busy": "2025-05-26T13:29:40.450191Z",
     "iopub.status.idle": "2025-05-26T13:29:40.455281Z",
     "shell.execute_reply": "2025-05-26T13:29:40.454596Z"
    },
    "papermill": {
     "duration": 0.014886,
     "end_time": "2025-05-26T13:29:40.456369",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.441483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- device & batch setup ---\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# use_gpu = (device.type == 'cuda')\n",
    "# batch_size = 1024\n",
    "\n",
    "# # --- move tensors to device ---\n",
    "# if use_gpu:\n",
    "#     all_f1 = all_f1.to(device)\n",
    "#     all_f2 = all_f2.to(device)\n",
    "#     all_f3 = all_f3.to(device)\n",
    "#     all_f4 = all_f4.to(device)\n",
    "# else:\n",
    "#     all_f1 = all_f1.cpu()\n",
    "#     all_f2 = all_f2.cpu()\n",
    "#     all_f3 = all_f3.cpu()\n",
    "#     all_f4 = all_f4.cpu()\n",
    "\n",
    "# # --- prepare mapping once ---\n",
    "# onehot_argmax = {v.values.argmax(): k for k, v in onehot.items()}\n",
    "# inv_map = {new_idx: onehot_argmax[orig_idx] for new_idx, orig_idx in enumerate(labels_idx)}\n",
    "\n",
    "# # --- validate label count ---\n",
    "# assert len(true_labels_list) == all_f1.size(0), \"Label/logit count mismatch\"\n",
    "\n",
    "# # --- 4. Generate weight combos ---\n",
    "# step = 0.01\n",
    "# min_w, max_w = 0, 1\n",
    "# weight_combos = []\n",
    "# w1 = min_w\n",
    "# while w1 <= max_w:\n",
    "#     w2 = min_w\n",
    "#     while w2 <= max_w:\n",
    "#         w3 = min_w\n",
    "#         while w3 <= max_w:\n",
    "#             w4 = round(1.0 - w1 - w2 - w3, 4)\n",
    "#             if 0 <= w4 <= 1.0:\n",
    "#                 weight_combos.append((round(w1,4), round(w2,4), round(w3,4), round(w4,4)))\n",
    "#             w3 = round(w3 + step, 4)\n",
    "#         w2 = round(w2 + step, 4)\n",
    "#     w1 = round(w1 + step, 4)\n",
    "\n",
    "# # --- 5. Search best weights ---\n",
    "# results = []\n",
    "# best_acc = 0.0\n",
    "# best_w = None\n",
    "# N = all_f1.size(0)\n",
    "\n",
    "# for w1, w2, w3, w4 in tqdm(weight_combos, desc=\"Searching weights\", dynamic_ncols=True):\n",
    "#     correct = 0\n",
    "#     for start in range(0, N, batch_size) if use_gpu else [0]:\n",
    "#         end = min(start + batch_size, N)\n",
    "#         # f1 = all_f1[start:end]\n",
    "#         # f2 = all_f2[start:end]\n",
    "#         # f3 = all_f3[start:end].squeeze()\n",
    "#         # f4 = all_f4[start:end]\n",
    "\n",
    "#         f1 = (all_f1[start:end] - all_f1[start:end].mean()) / (all_f1[start:end].std() + 1e-6)\n",
    "#         f2 = (all_f2[start:end] - all_f2[start:end].mean()) / (all_f2[start:end].std() + 1e-6)\n",
    "#         f3 = (all_f3[start:end] - all_f3[start:end].mean()) / (all_f3[start:end].std() + 1e-6)\n",
    "#         f4 = (all_f4[start:end] - all_f4[start:end].mean()) / (all_f4[start:end].std() + 1e-6)\n",
    "        \n",
    "#         final_logits = w1 * f1 + w2 * f2 + w3 * f3 + w4 * f4\n",
    "#         preds = final_logits.argmax(dim=-1).tolist()\n",
    "\n",
    "#         true_batch = true_labels_list[start:end]\n",
    "#         pred_labels = [inv_map[p] for p in preds]\n",
    "\n",
    "#         correct += sum(p == t for p, t in zip(pred_labels, true_batch))\n",
    "#         if not use_gpu:\n",
    "#             break\n",
    "\n",
    "#     acc = correct / N\n",
    "#     results.append((w1, w2, w3, w4, acc))\n",
    "#     if acc > best_acc:\n",
    "#         best_acc, best_w = acc, (w1, w2, w3, w4)\n",
    "\n",
    "# # New: Print top 5 best weights and accuracies\n",
    "# top5 = sorted(results, key=lambda x: x[-1], reverse=True)[:5]\n",
    "\n",
    "# print(\"\\nTop 5 best weights and accuracies:\")\n",
    "# for i, (w1, w2, w3, w4, acc) in enumerate(top5, 1):\n",
    "#     print(f\"{i}: Weights (LSTM={w1:.2f}, Linear={w2:.2f}, Tree={w3:.2f}, ResNet={w4:.2f}) - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# # --- 6. Display results ---\n",
    "# df_results = pd.DataFrame(results, columns=['LSTM','Linear','Tree','ResNet','accuracy'])\n",
    "# print(df_results)\n",
    "# print(f\"\\n✅ Best Weights {best_w}, Accuracy {best_acc:.4f}\")\n",
    "\n",
    "# # --- 7. 3D Scatter Plot ---\n",
    "# fig = plt.figure(figsize=(10,7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# sc = ax.scatter(df_results['Linear'], df_results['Tree'], df_results['ResNet'],\n",
    "#                 c=df_results['accuracy'], cmap='viridis', s=40)\n",
    "# ax.set_xlabel('Linear')\n",
    "# ax.set_ylabel('Tree')\n",
    "# ax.set_zlabel('ResNet')\n",
    "# ax.set_title('Accuracy vs Linear/Tree/ResNet Weights')\n",
    "# fig.colorbar(sc, ax=ax, label='Accuracy')\n",
    "# plt.show()\n",
    "\n",
    "# # --- 8. 2D Heatmap ---\n",
    "# fixed_lstm = best_w[0]\n",
    "# df_heat = df_results[df_results['LSTM']==fixed_lstm]\n",
    "# pivot = df_heat.pivot(index='Tree', columns='Linear', values='accuracy')\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.imshow(pivot, origin='lower', aspect='auto', cmap='viridis')\n",
    "# plt.xlabel('Linear Weight')\n",
    "# plt.ylabel('Tree Weight')\n",
    "# plt.title(f'Heatmap (LSTM={fixed_lstm:.2f})')\n",
    "# plt.colorbar(label='Accuracy')\n",
    "# plt.xticks(range(len(pivot.columns)), [f\"{x:.2f}\" for x in pivot.columns], rotation=90)\n",
    "# plt.yticks(range(len(pivot.index)), [f\"{y:.2f}\" for y in pivot.index])\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9351c45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.473084Z",
     "iopub.status.busy": "2025-05-26T13:29:40.472858Z",
     "iopub.status.idle": "2025-05-26T13:29:40.475843Z",
     "shell.execute_reply": "2025-05-26T13:29:40.475157Z"
    },
    "papermill": {
     "duration": 0.012525,
     "end_time": "2025-05-26T13:29:40.476985",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.464460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inv_map = {v.values.argmax(): k for k, v in onehot.items()}\n",
    "# len(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e1ec32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.493918Z",
     "iopub.status.busy": "2025-05-26T13:29:40.493484Z",
     "iopub.status.idle": "2025-05-26T13:29:40.497750Z",
     "shell.execute_reply": "2025-05-26T13:29:40.497050Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013935,
     "end_time": "2025-05-26T13:29:40.498850",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.484915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # --- Hyperparameters ---\n",
    "# step = 0.01\n",
    "# min_w, max_w = -3, 3  # weights range from 0 to 1\n",
    "\n",
    "# # --- 1. Generate weight combinations ---\n",
    "# weight_combos = []\n",
    "\n",
    "# w1 = min_w\n",
    "# while w1 <= max_w:\n",
    "#     w2 = min_w\n",
    "#     while w2 <= max_w:\n",
    "#         w3 = 1.0 - w1 - w2\n",
    "#         # Only keep combos where w3 >= 0 (weights sum to exactly 1)\n",
    "#         if w3 >= 0:\n",
    "#             weight_combos.append((round(w1, 4), round(w2, 4), round(w3, 4)))\n",
    "#         w2 = round(w2 + step, 4)\n",
    "#     w1 = round(w1 + step, 4)\n",
    "\n",
    "# # --- 2. Search best weights ---\n",
    "# results = []\n",
    "# best_acc = 0.0\n",
    "# best_w = None\n",
    "\n",
    "# for w1, w2, w3 in tqdm(weight_combos, desc=\"Searching weights\", dynamic_ncols=True):\n",
    "#     final_logits = w1 * all_f1 + w2 * all_f2 + w3 * all_f4  # [N, V]\n",
    "#     preds = final_logits.argmax(dim=1).tolist()\n",
    "\n",
    "#     onehot_argmax = {v.values.argmax(): k for k, v in onehot.items()}\n",
    "#     inv_map = {new_idx: onehot_argmax[orig_idx] for new_idx, orig_idx in enumerate(labels_idx)}\n",
    "#     pred_labels = [inv_map[p] for p in preds]\n",
    "\n",
    "#     correct = sum(pl == tl for pl, tl in zip(pred_labels, true_labels_list))\n",
    "#     acc = correct / len(true_labels_list)\n",
    "\n",
    "#     results.append((w1, w2, w3, acc))\n",
    "\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#         best_w = (w1, w2, w3)\n",
    "\n",
    "# # --- 3. Display results ---\n",
    "# df_results = pd.DataFrame(results, columns=['w1', 'w2', 'w3', 'accuracy'])\n",
    "# print(df_results)\n",
    "# print(f\"\\n✅ Best Weights {best_w}, Accuracy {best_acc:.4f}\")\n",
    "\n",
    "# # --- 4. 3D Scatter Plot ---\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# sc = ax.scatter(df_results['w1'], df_results['w2'], df_results['accuracy'],\n",
    "#                 c=df_results['accuracy'], cmap='viridis', s=40)\n",
    "# ax.set_xlabel('w1')\n",
    "# ax.set_ylabel('w2')\n",
    "# ax.set_zlabel('Accuracy')\n",
    "# ax.set_title('3D Scatter: Accuracy vs Weights (w3=1-w1-w2)')\n",
    "# fig.colorbar(sc, ax=ax, label='Accuracy')\n",
    "# plt.show()\n",
    "\n",
    "# # --- 5. 2D Heatmap ---\n",
    "# pivot = df_results.pivot(index='w1', columns='w2', values='accuracy')\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(pivot, origin='lower', aspect='auto', cmap='viridis')\n",
    "# plt.xlabel('w2')\n",
    "# plt.ylabel('w1')\n",
    "# plt.title('Heatmap of Accuracy (w3=1-w1-w2)')\n",
    "# plt.colorbar(label='Accuracy')\n",
    "# plt.xticks(ticks=range(len(pivot.columns)), labels=[f\"{x:.2f}\" for x in pivot.columns], rotation=90)\n",
    "# plt.yticks(ticks=range(len(pivot.index)), labels=[f\"{y:.2f}\" for y in pivot.index])\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12d1fcba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.515558Z",
     "iopub.status.busy": "2025-05-26T13:29:40.515180Z",
     "iopub.status.idle": "2025-05-26T13:29:40.518223Z",
     "shell.execute_reply": "2025-05-26T13:29:40.517555Z"
    },
    "papermill": {
     "duration": 0.01269,
     "end_time": "2025-05-26T13:29:40.519323",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.506633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef4a6045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.535805Z",
     "iopub.status.busy": "2025-05-26T13:29:40.535398Z",
     "iopub.status.idle": "2025-05-26T13:29:40.539535Z",
     "shell.execute_reply": "2025-05-26T13:29:40.538886Z"
    },
    "papermill": {
     "duration": 0.013569,
     "end_time": "2025-05-26T13:29:40.540655",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.527086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'annotation_id': ids,\n",
    "    'concept_name': predictions\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6b4e243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.557069Z",
     "iopub.status.busy": "2025-05-26T13:29:40.556872Z",
     "iopub.status.idle": "2025-05-26T13:29:40.565921Z",
     "shell.execute_reply": "2025-05-26T13:29:40.565094Z"
    },
    "papermill": {
     "duration": 0.018643,
     "end_time": "2025-05-26T13:29:40.567148",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.548505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>concept_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pandalus amplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Funiculina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Funiculina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Funiculina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Funiculina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>784</td>\n",
       "      <td>Lithodidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>785</td>\n",
       "      <td>Delectopecten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>786</td>\n",
       "      <td>Scotoplanes globosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>787</td>\n",
       "      <td>Sebastolobus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>788</td>\n",
       "      <td>Octopus rubescens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotation_id         concept_name\n",
       "0                1      Pandalus amplus\n",
       "1                2           Funiculina\n",
       "2                3           Funiculina\n",
       "3                4           Funiculina\n",
       "4                5           Funiculina\n",
       "..             ...                  ...\n",
       "783            784           Lithodidae\n",
       "784            785        Delectopecten\n",
       "785            786  Scotoplanes globosa\n",
       "786            787         Sebastolobus\n",
       "787            788    Octopus rubescens\n",
       "\n",
       "[788 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffc7923d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.584343Z",
     "iopub.status.busy": "2025-05-26T13:29:40.583775Z",
     "iopub.status.idle": "2025-05-26T13:29:40.586767Z",
     "shell.execute_reply": "2025-05-26T13:29:40.586259Z"
    },
    "papermill": {
     "duration": 0.012496,
     "end_time": "2025-05-26T13:29:40.587788",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.575292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Accuracy = number of correct predictions / total predictions\n",
    "# correct = (submission_df['annotation_id'] == submission_df['concept_name']).sum()\n",
    "# total = len(submission_df)\n",
    "\n",
    "# accuracy = correct / total\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7b7f4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.604441Z",
     "iopub.status.busy": "2025-05-26T13:29:40.604245Z",
     "iopub.status.idle": "2025-05-26T13:29:40.612372Z",
     "shell.execute_reply": "2025-05-26T13:29:40.611890Z"
    },
    "papermill": {
     "duration": 0.017807,
     "end_time": "2025-05-26T13:29:40.613520",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.595713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39abe2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:29:40.631180Z",
     "iopub.status.busy": "2025-05-26T13:29:40.630968Z",
     "iopub.status.idle": "2025-05-26T13:29:40.634407Z",
     "shell.execute_reply": "2025-05-26T13:29:40.633742Z"
    },
    "papermill": {
     "duration": 0.013514,
     "end_time": "2025-05-26T13:29:40.635568",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.622054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the matrix\n",
    "# pf = pd.read_csv('/kaggle/input/fathomnet-dataset/Taxonomic_metric (1).csv', index_col=0)\n",
    "\n",
    "# total_score = 0.0\n",
    "# count = 0\n",
    "# for i in range(len(submission_df)):\n",
    "#     true, predict = submission_df.iloc[i]\n",
    "#     if true != predict:\n",
    "#         total_score += pf.loc[true, predict]\n",
    "#         count += 1\n",
    "# score = total_score/len(submission_df)\n",
    "# score_false = total_score/count\n",
    "# print(\"Score: \", score)\n",
    "# print(\"Score in false: \", score_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ea6aa",
   "metadata": {
    "papermill": {
     "duration": 0.007704,
     "end_time": "2025-05-26T13:29:40.651274",
     "exception": false,
     "start_time": "2025-05-26T13:29:40.643570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11305476,
     "sourceId": 88612,
     "sourceType": "competition"
    },
    {
     "datasetId": 7125806,
     "sourceId": 11793354,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7512150,
     "sourceId": 11949070,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 309887,
     "modelInstanceId": 317867,
     "sourceId": 392388,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 309887,
     "modelInstanceId": 289146,
     "sourceId": 392232,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 309887,
     "modelInstanceId": 315559,
     "sourceId": 392239,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 250.364228,
   "end_time": "2025-05-26T13:29:44.263824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T13:25:33.899596",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c148e0e274470fb19b24d4fc7dac83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "133750a02cfb4e83a9dca2142ba1a043": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18af7c24c3474d309e6c884f5f96138d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c8b1cffc14140e183b07e244b52e72c",
       "placeholder": "​",
       "style": "IPY_MODEL_9ef1337b4a4146b48ce383c80a97484d",
       "tabbable": null,
       "tooltip": null,
       "value": " 445M/445M [00:01&lt;00:00, 333MB/s]"
      }
     },
     "1e5093da52c14ebcb069b408b55b5b77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9adb08ab03914f53a509ca91af1f4d47",
       "placeholder": "​",
       "style": "IPY_MODEL_5a35fc46db984973ac2c0f889c55fe3a",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "2b325fc5343c4214a00137355d5a9d4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_133750a02cfb4e83a9dca2142ba1a043",
       "placeholder": "​",
       "style": "IPY_MODEL_00c148e0e274470fb19b24d4fc7dac83",
       "tabbable": null,
       "tooltip": null,
       "value": " 788M/788M [00:02&lt;00:00, 307MB/s]"
      }
     },
     "2c8f97e1bf8845bf9572d5bece77c8e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1ab0bce15404e2b8ceb84a610527479",
       "placeholder": "​",
       "style": "IPY_MODEL_8efd7d75593f4f71849a649a3e0db110",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "3d5834cc1b64441e90b5ebe0e291182a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e1cf7252105f4e998a386a56ff0a2bea",
       "max": 787742820.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d554efad023249acb13307f70e556212",
       "tabbable": null,
       "tooltip": null,
       "value": 787742820.0
      }
     },
     "4e89649d09434ca1ad39f3024264b0da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e5093da52c14ebcb069b408b55b5b77",
        "IPY_MODEL_3d5834cc1b64441e90b5ebe0e291182a",
        "IPY_MODEL_2b325fc5343c4214a00137355d5a9d4e"
       ],
       "layout": "IPY_MODEL_deb305f4b772473b86c0241d58b9303c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5a35fc46db984973ac2c0f889c55fe3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "666e393c88ba41769e8fa1ed943c97bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7bbd6901cb9246c3baad75bd4b70c596": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c8b1cffc14140e183b07e244b52e72c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8efd7d75593f4f71849a649a3e0db110": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9adb08ab03914f53a509ca91af1f4d47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ef1337b4a4146b48ce383c80a97484d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c63cac608d2c4b3483646b132b7aa4fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d083e09b438e445094b641c233730584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c63cac608d2c4b3483646b132b7aa4fe",
       "max": 445210460.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_666e393c88ba41769e8fa1ed943c97bf",
       "tabbable": null,
       "tooltip": null,
       "value": 445210460.0
      }
     },
     "d554efad023249acb13307f70e556212": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "deb305f4b772473b86c0241d58b9303c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1cf7252105f4e998a386a56ff0a2bea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1ab0bce15404e2b8ceb84a610527479": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f51e048a3006488eac5c48568f2aec0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c8f97e1bf8845bf9572d5bece77c8e4",
        "IPY_MODEL_d083e09b438e445094b641c233730584",
        "IPY_MODEL_18af7c24c3474d309e6c884f5f96138d"
       ],
       "layout": "IPY_MODEL_7bbd6901cb9246c3baad75bd4b70c596",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
