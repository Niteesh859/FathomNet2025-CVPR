{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27d0c4d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:36.644419Z",
     "iopub.status.busy": "2025-05-25T18:17:36.644140Z",
     "iopub.status.idle": "2025-05-25T18:17:36.648225Z",
     "shell.execute_reply": "2025-05-25T18:17:36.647526Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.014821,
     "end_time": "2025-05-25T18:17:36.649426",
     "exception": false,
     "start_time": "2025-05-25T18:17:36.634605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r ../input/fathomnet-2025/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33d524c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:36.665187Z",
     "iopub.status.busy": "2025-05-25T18:17:36.664751Z",
     "iopub.status.idle": "2025-05-25T18:17:38.350404Z",
     "shell.execute_reply": "2025-05-25T18:17:38.349638Z"
    },
    "papermill": {
     "duration": 1.694661,
     "end_time": "2025-05-25T18:17:38.351824",
     "exception": false,
     "start_time": "2025-05-25T18:17:36.657163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install open-clip-torch\n",
    "# import open_clip\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54980552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.368173Z",
     "iopub.status.busy": "2025-05-25T18:17:38.367819Z",
     "iopub.status.idle": "2025-05-25T18:17:38.382342Z",
     "shell.execute_reply": "2025-05-25T18:17:38.381613Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.024091,
     "end_time": "2025-05-25T18:17:38.383543",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.359452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_mapping = {\n",
    "    \"Vesicomyidae\": [\"Animalia\", \"Mollusca\", \"Bivalvia\", \"Veneroida\", \"Vesicomyidae\"],\n",
    "    \"Sebastolobus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastolobus\"],\n",
    "    \"Apostichopus leukothele\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Stichopodidae\", \"Apostichopus leukothele\"],\n",
    "    \"Scotoplanes\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Scotoplanes\"],\n",
    "    \"Keratoisis\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Keratoisidae\", \"Keratoisis\"],\n",
    "    \"Munnopsidae\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Isopoda\", \"Munnopsidae\"],\n",
    "    \"Scotoplanes globosa\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Scotoplanes globosa\"],\n",
    "    \"Mediaster aequalis\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Mediaster aequalis\"],\n",
    "    \"Asbestopluma monticola\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Asbestopluma\", \"Asbestopluma monticola\"],\n",
    "    \"Acanthascinae\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Valvatida\", \"Acanthasteridae\", \"Acanthascinae\"],\n",
    "    \"Florometra serratissima\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Antedonidae\", \"Florometra serratissima\"],\n",
    "    \"Psathyrometra fragilis\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Antedonidae\", \"Psathyrometra fragilis\"],\n",
    "    \"Zoantharia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Zoantharia\"],\n",
    "    \"Gersemia juliepackardae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Gersemia juliepackardae\"],\n",
    "    \"Pandalus platyceros\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Pandalidae\", \"Pandalus platyceros\"],\n",
    "    \"Isidella tentaculum\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Isidella tentaculum\"],\n",
    "    \"Holothuroidea\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\"],\n",
    "    \"Paragorgia arborea\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\", \"Paragorgia arborea\"],\n",
    "    \"Heterochone calyx\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Heterochone calyx\"],\n",
    "    \"Paragorgia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\", \"Paragorgia\"],\n",
    "    \"Terebellidae\": [\"Animalia\", \"Annelida\", \"Polychaeta\", \"Terebellida\", \"Terebellidae\"],\n",
    "    \"Ophiuroidea\": [\"Animalia\", \"Echinodermata\", \"Ophiuroidea\"],\n",
    "    \"Peniagone\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Peniagone\"],\n",
    "    \"Actiniaria\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\"],\n",
    "    \"Ceriantharia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Ceriantharia\"],\n",
    "    \"Isididae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Isididae\"],\n",
    "    \"Rathbunaster californicus\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Rathbunaster californicus\"],\n",
    "    \"Paelopatides confundens\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Paelopatides confundens\"],\n",
    "    \"Abyssocucumis abyssorum\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Aspidochirotida\", \"Stichopodidae\", \"Abyssocucumis abyssorum\"],\n",
    "    \"Strongylocentrotus fragilis\": [\"Animalia\", \"Echinodermata\", \"Echinoidea\", \"Clypeasteroida\", \"Strongylocentrotidae\", \"Strongylocentrotus fragilis\"],\n",
    "    \"Porifera\": [\"Animalia\", \"Porifera\"],\n",
    "    \"Psolus squamatus\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Stichopodidae\", \"Psolus squamatus\"],\n",
    "    \"Liponema brevicorne\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Dendrochirotida\", \"Elasipodidae\", \"Liponema brevicorne\"],\n",
    "    \"Farrea\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Farrea\"],\n",
    "    \"Caridea\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Caridea\"],\n",
    "    \"Hexactinellida\": [\"Animalia\", \"Porifera\", \"Hexactinellida\"],\n",
    "    \"Actinernus\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Forcipulatida\", \"Asteriidae\", \"Actinernus\"],\n",
    "    \"Pannychia moseleyi\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Pannychia moseleyi\"],\n",
    "    \"Gastropoda\": [\"Animalia\", \"Mollusca\", \"Gastropoda\"],\n",
    "    \"Benthocodon pedunculata\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Leptomedusae\", \"Benthocodon pedunculata\"],\n",
    "    \"Octopus rubescens\": [\"Animalia\", \"Mollusca\", \"Cephalopoda\", \"Octopodiformes\", \"Octopodidae\", \"Octopus rubescens\"],\n",
    "    \"Microstomus pacificus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Pleuronectiformes\", \"Paralichthyidae\", \"Microstomus pacificus\"],\n",
    "    \"Heteropolypus ritteri\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Hydridae\", \"Heteropolypus ritteri\"],\n",
    "    \"Parastenella\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Hydridae\", \"Parastenella\"],\n",
    "    \"Staurocalyptus\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidolina\", \"Staurocalyptidae\", \"Staurocalyptus\"],\n",
    "    \"Hormathiidae\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\", \"Hormathiidae\"],\n",
    "    \"Scleractinia\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Scleractinia\"],\n",
    "    \"Asbestopluma\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Verongimorpha\", \"Asbestopluma\"],\n",
    "    \"Isosicyonis\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Isosicyonis\"],\n",
    "    \"Umbellula\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Gorgonacea\", \"Umbellulidae\", \"Umbellula\"],\n",
    "    \"Sebastes\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastes\"],\n",
    "    \"Metridium farcimen\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Actiniaria\", \"Metridiidae\", \"Metridium farcimen\"],\n",
    "    \"Merluccius productus\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Gadiformes\", \"Gadidae\", \"Merluccius productus\"],\n",
    "    \"Funiculina\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\", \"Comatulida\", \"Funiculinidae\", \"Funiculina\"],\n",
    "    \"Brisingida\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Brisingida\"],\n",
    "    \"Pyrosoma atlanticum\": [\"Animalia\", \"Chordata\", \"Tunicates\", \"Pyrosomida\", \"Pyrosomatidae\", \"Pyrosoma atlanticum\"],\n",
    "    \"Acanthoptilum\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Perciformes\", \"Acanthoptilidae\", \"Acanthoptilum\"],\n",
    "    \"Actinopterygii\": [\"Animalia\", \"Chordata\", \"Actinopterygii\"],\n",
    "    \"Chorilia longipes\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Alcyonacea\", \"Isididae\", \"Chorilia longipes\"],\n",
    "    \"Paralomis multispina\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Lithodidae\", \"Paralomis multispina\"],\n",
    "    \"Sebastes diploproa\": [\"Animalia\", \"Chordata\", \"Actinopterygii\", \"Scorpaeniformes\", \"Sebastidae\", \"Sebastes diploproa\"],\n",
    "    \"Mycale\": [\"Animalia\", \"Porifera\", \"Demospongiae\", \"Haplosclerida\", \"Mycalidae\", \"Mycale\"],\n",
    "    \"Lithodidae\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Lithodidae\"],\n",
    "    \"Ophiacanthidae\": [\"Animalia\", \"Echinodermata\", \"Ophiuroidea\", \"Ophiacanthidae\"],\n",
    "    \"Corallimorphus pilatus\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Corallimorpharia\", \"Corallimorphidae\", \"Corallimorphus pilatus\"],\n",
    "    \"Ptychogastria polaris\": [\"Animalia\", \"Cnidaria\", \"Hydrozoa\", \"Hydroidea\", \"Ptychogastriidae\", \"Ptychogastria polaris\"],\n",
    "    \"Amphipoda\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Amphipoda\"],\n",
    "    \"Heterocarpus\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Heterocarpoidea\", \"Heterocarpus\"],\n",
    "    \"Pennatula phosphorea\": [\"Animalia\", \"Cnidaria\", \"Anthozoa\", \"Pennatulacea\", \"Pennatulidae\", \"Pennatula phosphorea\"],\n",
    "    \"Chionoecetes tanneri\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Oregoniidae\", \"Chionoecetes tanneri\"],\n",
    "    \"Hippasteria\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\", \"Valvatida\", \"Asteriidae\", \"Hippasteria\"],\n",
    "    \"Munidopsis\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Munidopsidae\", \"Munidopsis\"],\n",
    "    \"Serpulidae\": [\"Animalia\", \"Annelida\", \"Polychaeta\", \"Canalipalpata\", \"Serpulidae\"],\n",
    "    \"Delectopecten\": [\"Animalia\", \"Mollusca\", \"Bivalvia\", \"Pectinida\", \"Pectinidae\", \"Delectopecten\"],\n",
    "    \"Crinoidea\": [\"Animalia\", \"Echinodermata\", \"Crinoidea\"],\n",
    "    \"Tunicata\": [\"Animalia\", \"Chordata\", \"Tunicata\"],\n",
    "    \"Asteroidea\": [\"Animalia\", \"Echinodermata\", \"Asteroidea\"],\n",
    "    \"Pandalus amplus\": [\"Animalia\", \"Arthropoda\", \"Malacostraca\", \"Decapoda\", \"Pandalidae\", \"Pandalus amplus\"],\n",
    "    \"Elpidia\": [\"Animalia\", \"Echinodermata\", \"Holothuroidea\", \"Aspidochirotida\", \"Stichopodidae\", \"Elpidia\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1371d611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.399267Z",
     "iopub.status.busy": "2025-05-25T18:17:38.398806Z",
     "iopub.status.idle": "2025-05-25T18:17:38.557978Z",
     "shell.execute_reply": "2025-05-25T18:17:38.557172Z"
    },
    "papermill": {
     "duration": 0.168411,
     "end_time": "2025-05-25T18:17:38.559389",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.390978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/kaggle/input/fathomnet-2025/dataset_train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "id_to_name = {i: category['name'] for i, category in enumerate(data['categories'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42fe76d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.575434Z",
     "iopub.status.busy": "2025-05-25T18:17:38.575169Z",
     "iopub.status.idle": "2025-05-25T18:17:38.579257Z",
     "shell.execute_reply": "2025-05-25T18:17:38.578593Z"
    },
    "papermill": {
     "duration": 0.013478,
     "end_time": "2025-05-25T18:17:38.580383",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.566905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = list(tree_mapping.keys())\n",
    "# k = 0\n",
    "# for i in range(len(keys)):\n",
    "#     k = max(len(tree_mapping[keys[i]]), k)\n",
    "for i in range(len(keys)):\n",
    "    tree_mapping[keys[i]].append(\"spl_stp\")\n",
    "    tree_mapping[keys[i]] += [\"-\"] * (7 - len(tree_mapping[keys[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fce74f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.595633Z",
     "iopub.status.busy": "2025-05-25T18:17:38.595391Z",
     "iopub.status.idle": "2025-05-25T18:17:38.622682Z",
     "shell.execute_reply": "2025-05-25T18:17:38.621827Z"
    },
    "papermill": {
     "duration": 0.036119,
     "end_time": "2025-05-25T18:17:38.623940",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.587821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus_Species\", \"spl\"]\n",
    "df = pd.DataFrame.from_dict(tree_mapping, orient='index', columns=columns)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Taxon'}, inplace=True)\n",
    "unique_elements = pd.unique(df.values.ravel())\n",
    "onehot = dict(pd.get_dummies(unique_elements).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cc1547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.639377Z",
     "iopub.status.busy": "2025-05-25T18:17:38.639117Z",
     "iopub.status.idle": "2025-05-25T18:17:38.647409Z",
     "shell.execute_reply": "2025-05-25T18:17:38.646803Z"
    },
    "papermill": {
     "duration": 0.017139,
     "end_time": "2025-05-25T18:17:38.648456",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.631317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_idx = [argmax.idxmax() for argmax in [onehot.get(key.split()[-1], onehot.get(key, None)) for key in tree_mapping] if argmax is not None]\n",
    "len(labels_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090f7e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.664648Z",
     "iopub.status.busy": "2025-05-25T18:17:38.664176Z",
     "iopub.status.idle": "2025-05-25T18:17:38.669106Z",
     "shell.execute_reply": "2025-05-25T18:17:38.668554Z"
    },
    "papermill": {
     "duration": 0.014197,
     "end_time": "2025-05-25T18:17:38.670179",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.655982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(list(tree_mapping.keys()))):\n",
    "    for j in range(7):\n",
    "        tree_mapping[list(tree_mapping.keys())[i]][j] = onehot[tree_mapping[list(tree_mapping.keys())[i]][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19dbe17",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:38.685288Z",
     "iopub.status.busy": "2025-05-25T18:17:38.685083Z",
     "iopub.status.idle": "2025-05-25T18:17:56.980532Z",
     "shell.execute_reply": "2025-05-25T18:17:56.979414Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 18.307317,
     "end_time": "2025-05-25T18:17:56.984664",
     "exception": false,
     "start_time": "2025-05-25T18:17:38.677347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e52bcf5f2584d468da5f10a9fc5a299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNestBottleneck(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNestBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNestBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNestBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNestBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (36): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (37): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (38): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (39): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (40): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (41): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (42): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (43): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (44): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (45): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (46): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (47): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNestBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): ResNestBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): SplitAttn(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Identity()\n",
       "        (act0): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): RadixSoftmax()\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (drop_block): Identity()\n",
       "      (act2): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model('resnest269e.in1k', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0d10fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.006465Z",
     "iopub.status.busy": "2025-05-25T18:17:57.006196Z",
     "iopub.status.idle": "2025-05-25T18:17:57.012334Z",
     "shell.execute_reply": "2025-05-25T18:17:57.011718Z"
    },
    "papermill": {
     "duration": 0.018231,
     "end_time": "2025-05-25T18:17:57.013486",
     "exception": false,
     "start_time": "2025-05-25T18:17:56.995255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data transformations for preprocessing For other models\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # EfficientNetV2-M expects 224x224 input\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Marine life often has left/right symmetry\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),  # Simulates light variation underwater\n",
    "    transforms.RandomRotation(degrees=10),  # Slight rotation\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # Mild zoom/pan\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# For validation/test (no augmentations, just resizing and normalization)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c885bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.034759Z",
     "iopub.status.busy": "2025-05-25T18:17:57.034513Z",
     "iopub.status.idle": "2025-05-25T18:17:57.387689Z",
     "shell.execute_reply": "2025-05-25T18:17:57.386830Z"
    },
    "papermill": {
     "duration": 0.364831,
     "end_time": "2025-05-25T18:17:57.389200",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.024369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/kaggle/input/fathomnet-2025/dataset_train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "id_to_name = {i: category['name'] for i, category in enumerate(data['categories'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d884c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.408981Z",
     "iopub.status.busy": "2025-05-25T18:17:57.408695Z",
     "iopub.status.idle": "2025-05-25T18:17:57.415402Z",
     "shell.execute_reply": "2025-05-25T18:17:57.414875Z"
    },
    "papermill": {
     "duration": 0.01774,
     "end_time": "2025-05-25T18:17:57.416505",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.398765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "\n",
    "class FathomNetDataset_tkn(Dataset):\n",
    "    def __init__(self, csv_path, transformation=None, is_test=False, tree_map=tree_mapping):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transformation\n",
    "        self.is_test = is_test\n",
    "        self.image_paths = self.data[\"path\"].tolist()\n",
    "        self.num_class = len(list(tree_map.keys()))\n",
    "\n",
    "        if not is_test:\n",
    "            self.labels = self.data[\"label\"]\n",
    "            # one_hot = pd.get_dummies(self.labels)\n",
    "            self.updated_labels = self.labels.map(lambda x: tree_mapping[x])\n",
    "            # self.class_mapping = dict(enumerate(one_hot.columns.tolist()))\n",
    "            # self.class_mapping = tree_map\n",
    "        else:\n",
    "            self.labels = None\n",
    "            self.label_encoded = None\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        img_trans = self.transform(img) if self.transform else img\n",
    "    \n",
    "        if self.is_test:\n",
    "            return img_trans, self.image_paths[idx]\n",
    "        else:\n",
    "            label = self.updated_labels[idx]\n",
    "            label_tensor = torch.tensor(label)\n",
    "            return img_trans, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed2d069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.435455Z",
     "iopub.status.busy": "2025-05-25T18:17:57.435198Z",
     "iopub.status.idle": "2025-05-25T18:17:57.439126Z",
     "shell.execute_reply": "2025-05-25T18:17:57.438544Z"
    },
    "papermill": {
     "duration": 0.014737,
     "end_time": "2025-05-25T18:17:57.440261",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.425524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# class FathomNetDataset_indep(Dataset):\n",
    "#     \"\"\"\n",
    "#     A custom PyTorch Dataset for loading images and labels from a CSV file for training or testing.\n",
    "\n",
    "#     Args:\n",
    "#         csv_path (str): Path to the CSV file containing image paths and labels.\n",
    "#         transform (callable, optional): Optional image transformations to apply.\n",
    "#         label_encoder (LabelEncoder, optional): Optional pre-fitted LabelEncoder for consistent label mapping.\n",
    "#         is_test (bool): Flag indicating whether the dataset is for testing (no labels).\n",
    "\n",
    "#     CSV Requirements:\n",
    "#         - Must contain a \"path\" column with image file paths.\n",
    "#         - If not in test mode, must contain a \"label\" column with class labels.\n",
    "\n",
    "#     Returns:\n",
    "#         - If `is_test` is False: a tuple (image, encoded_label).\n",
    "#         - If `is_test` is True: a tuple (image, image_path).\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, csv_path, transform=None, label_encoder=None, is_test=False):\n",
    "#         self.data = pd.read_csv(csv_path)\n",
    "#         self.transform = transform\n",
    "#         self.is_test = is_test\n",
    "\n",
    "#         self.image_paths = self.data[\"path\"].tolist()\n",
    "\n",
    "#         if not is_test:\n",
    "#             self.labels = self.data[\"label\"].tolist()\n",
    "#             # Use provided label encoder or fit one\n",
    "#             if label_encoder is None:\n",
    "#                 self.label_encoder = LabelEncoder()\n",
    "#                 self.label_ids = self.label_encoder.fit_transform(self.labels)\n",
    "#             else:\n",
    "#                 self.label_encoder = label_encoder\n",
    "#                 self.label_ids = self.label_encoder.transform(self.labels)\n",
    "#         else:\n",
    "#             self.labels = None\n",
    "#             self.label_ids = None\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         if self.is_test:\n",
    "#             return image, self.image_paths[idx]\n",
    "#         else:\n",
    "#             label = self.label_ids[idx]\n",
    "#             return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a424dafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.459950Z",
     "iopub.status.busy": "2025-05-25T18:17:57.459669Z",
     "iopub.status.idle": "2025-05-25T18:17:57.463543Z",
     "shell.execute_reply": "2025-05-25T18:17:57.462944Z"
    },
    "papermill": {
     "duration": 0.015159,
     "end_time": "2025-05-25T18:17:57.464534",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.449375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "\n",
    "\n",
    "# class FathomNetDataset(Dataset):\n",
    "#     def __init__(self, csv_path, transformation=None, label_encoder=None, is_test=False):\n",
    "#         self.data = pd.read_csv(csv_path)\n",
    "#         self.transform = transformation\n",
    "#         self.is_test = is_test\n",
    "#         self.image_paths = self.data[\"path\"].tolist()\n",
    "\n",
    "#         if not is_test:\n",
    "#             # Encoding the labels\n",
    "#             self.labels = self.data[\"label\"]\n",
    "#             one_hot = pd.get_dummies(self.labels)\n",
    "#             self.num_class = len(one_hot.columns)\n",
    "#             self.class_mapping = dict(enumerate(one_hot.columns.tolist()))\n",
    "#             if label_encoder is None:\n",
    "#                 self.label_encoded = torch.tensor(one_hot.values, dtype=torch.float)\n",
    "#             else:\n",
    "#                 encoded_labels = label_encoder.transform(self.labels)\n",
    "#                 self.label_encoded = torch.tensor(encoded_labels, dtype=torch.long)\n",
    "\n",
    "#         else:\n",
    "#             self.labels = None\n",
    "#             self.label_encoded = None\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "#         img_trans = self.transform(img) if self.transform else img\n",
    "\n",
    "#         if self.is_test:\n",
    "#             return img_trans, self.image_paths[idx]\n",
    "#         else: \n",
    "#             return img_trans, self.label_encoded[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274e4032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.483227Z",
     "iopub.status.busy": "2025-05-25T18:17:57.483028Z",
     "iopub.status.idle": "2025-05-25T18:17:57.488181Z",
     "shell.execute_reply": "2025-05-25T18:17:57.487478Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015781,
     "end_time": "2025-05-25T18:17:57.489211",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.473430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models, transforms\n",
    "# from torchvision.models import EfficientNet_V2_M_Weights\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from torchvision.models import swin_t, Swin_T_Weights\n",
    "# from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "# import timm\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "\n",
    "# class ChildSumTreeLSTMCell(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.child_num = max_len\n",
    "\n",
    "#         self.W_i = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_f = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_o = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "#         self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "#         self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "#     def forward(self, x, child_h, child_c):\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "#         zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "#         zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "#         actual_len = len(child_h)\n",
    "#         child_h = child_h + [zero_h] * (self.child_num - actual_len)\n",
    "#         child_c = child_c + [zero_c] * (self.child_num - actual_len)\n",
    "\n",
    "#         i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(actual_len)) + self.b_i\n",
    "#         o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(actual_len)) + self.b_o\n",
    "#         u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(actual_len)) + self.b_u\n",
    "\n",
    "#         i = torch.sigmoid(i_input)\n",
    "#         o = torch.sigmoid(o_input)\n",
    "#         u = torch.tanh(u_input)\n",
    "\n",
    "#         c = i * u\n",
    "#         for k in range(actual_len):\n",
    "#             f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "#             c += f_k * child_c[k]\n",
    "\n",
    "#         h = o * torch.tanh(c)\n",
    "#         return h, c\n",
    "\n",
    "\n",
    "# class FathomnetClassResnet(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.stop_tkn_idx = stop_tkn_idx\n",
    "#         self.pad_tkn_idx = pad_tkn_idx\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#         # EfficientNet backbone\n",
    "#         backbone = timm.create_model(\"resnest269e\", pretrained=True, num_classes=0)  # num_classes=0 disables classifier\n",
    "#         self.feature_extractor = nn.Sequential(\n",
    "#             backbone,  # full model will just return features\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "#         feat_dim = backbone.num_features  # e.g., 1280 for B0\n",
    "\n",
    "#         self.img_proj = nn.Linear(feat_dim, hidden_size)\n",
    "\n",
    "#         # Token embedding\n",
    "#         self.token_emb = nn.Embedding(vocab_size, hidden_size)\n",
    "#         self.start_token = nn.Parameter(torch.randn(1, hidden_size))\n",
    "\n",
    "#         # TreeLSTM\n",
    "#         self.tree_cell = ChildSumTreeLSTMCell(input_size=hidden_size, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "#         # Classifier\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "#         self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x, targets=None):\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "\n",
    "#         # 1. Encode image\n",
    "#         feats = self.feature_extractor(x)  # [B, feat_dim]\n",
    "#         img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "#         img_c = torch.zeros_like(img_h)\n",
    "\n",
    "#         hidden_states = [img_h]\n",
    "#         cell_states = [img_c]\n",
    "#         logits_list = []\n",
    "\n",
    "#         done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "#         current_token = self.start_token.expand(batch_size, -1)\n",
    "\n",
    "#         for t in range(self.max_len):\n",
    "#             h_t, c_t = self.tree_cell(current_token, hidden_states, cell_states)\n",
    "#             hidden_states.append(h_t)\n",
    "#             cell_states.append(c_t)\n",
    "\n",
    "#             logits = self.fc(h_t)  # [B, V]\n",
    "#             logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "#             if targets is not None:\n",
    "#                 # Teacher forcing\n",
    "#                 current_token = self.token_emb(targets[:, t])\n",
    "#             else:\n",
    "#                 # Inference\n",
    "#                 preds = torch.argmax(logits, dim=1)\n",
    "#                 done |= (preds == self.stop_tkn_idx)\n",
    "#                 current_token = self.token_emb(preds)\n",
    "#                 if done.all():\n",
    "#                     break\n",
    "\n",
    "#         output = torch.cat(logits_list, dim=1)\n",
    "\n",
    "#         if targets is not None:\n",
    "#             loss = self.loss(output.view(-1, self.vocab_size), targets.view(-1))\n",
    "#             return output, loss\n",
    "\n",
    "#         # Pad if needed\n",
    "#         pad_len = self.max_len - output.size(1)\n",
    "#         if pad_len > 0:\n",
    "#             pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "#             pad_logits[:, :, self.pad_tkn_idx] = 1\n",
    "#             output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "#         return output  # [B, max_len, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b0409e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.508318Z",
     "iopub.status.busy": "2025-05-25T18:17:57.508099Z",
     "iopub.status.idle": "2025-05-25T18:17:57.513291Z",
     "shell.execute_reply": "2025-05-25T18:17:57.512626Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015942,
     "end_time": "2025-05-25T18:17:57.514372",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.498430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models, transforms\n",
    "# from torchvision.models import EfficientNet_V2_M_Weights\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from transformers import AutoProcessor, AutoModel\n",
    "# from torchvision.transforms import ToPILImage\n",
    "\n",
    "# class ChildSumTreeLSTMCell(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.child_num = max_len  # max number of children\n",
    "\n",
    "#         # Input projections\n",
    "#         self.W_i = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_f = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_o = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "#         # Distinct hidden projections per child (indexed by position)\n",
    "#         self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "#         # Bias terms\n",
    "#         self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "#     def forward(self, x, child_h, child_c):\n",
    "#         # Pad child_h and child_c with zeros up to self.child_num\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "#         zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "#         zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "#         # Fill missing child states\n",
    "#         child_h = child_h + [zero_h] * (self.child_num - len(child_h))\n",
    "#         child_c = child_c + [zero_c] * (self.child_num - len(child_c))\n",
    "\n",
    "#         # Sum over active children only (i.e., up to original len)\n",
    "#         active_len = len(child_h) - (self.child_num - len(child_h))\n",
    "\n",
    "#         # Gates\n",
    "#         i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(active_len)) + self.b_i\n",
    "#         o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(active_len)) + self.b_o\n",
    "#         u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(active_len)) + self.b_u\n",
    "\n",
    "#         i = torch.sigmoid(i_input)\n",
    "#         o = torch.sigmoid(o_input)\n",
    "#         u = torch.tanh(u_input)\n",
    "\n",
    "#         # Forget gates and new cell state\n",
    "#         c = i * u\n",
    "#         for k in range(active_len):\n",
    "#             f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "#             c += f_k * child_c[k]\n",
    "\n",
    "#         h = o * torch.tanh(c)\n",
    "#         return h, c\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "# class FathomnetClassSigLIP(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.stop_tkn_idx = stop_tkn_idx\n",
    "#         self.pad_tkn_idx = pad_tkn_idx\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#         # Save processor and model as attributes\n",
    "#         self.preprocessor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "#         self.base = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "\n",
    "#         # Project image features to LSTM hidden size\n",
    "#         self.img_proj = nn.Linear(input_dim, hidden_size)\n",
    "\n",
    "#         # TreeLSTM cell (you have this implemented elsewhere)\n",
    "#         self.tree_cell = ChildSumTreeLSTMCell(input_size=input_dim, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "#         # Final classifier head\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "#         self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     def forward(self, images, tree_structure=None):\n",
    "#         device = images.device if isinstance(images, torch.Tensor) else None\n",
    "    \n",
    "#         if isinstance(images, torch.Tensor):\n",
    "#             to_pil = ToPILImage()\n",
    "#             images = [to_pil(img.cpu()) for img in images]\n",
    "    \n",
    "#         dummy_texts = [\"\"] * len(images)\n",
    "#         inputs = self.preprocessor(text=dummy_texts, images=images, return_tensors=\"pt\")\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "#         outputs = self.base(**inputs)\n",
    "#         feats = outputs.image_embeds  # <-- changed here\n",
    "    \n",
    "#         img_h = torch.tanh(self.img_proj(feats))\n",
    "#         img_c = torch.zeros_like(img_h)\n",
    "    \n",
    "#         hidden_states = [img_h]\n",
    "#         cell_states = [img_c]\n",
    "#         logits_list = []\n",
    "    \n",
    "#         batch_size = feats.size(0)\n",
    "#         done = torch.zeros(batch_size, dtype=torch.bool, device=feats.device)\n",
    "    \n",
    "#         for t in range(self.max_len):\n",
    "#             h_t, c_t = self.tree_cell(feats, hidden_states, cell_states)\n",
    "#             hidden_states.append(h_t)\n",
    "#             cell_states.append(c_t)\n",
    "    \n",
    "#             logits = self.fc(h_t)  # [B, vocab_size]\n",
    "#             logits_list.append(logits.unsqueeze(1))\n",
    "    \n",
    "#             preds = torch.argmax(logits, dim=1)\n",
    "#             done |= (preds == self.stop_tkn_idx)\n",
    "#             if done.all():\n",
    "#                 break\n",
    "    \n",
    "#         output = torch.cat(logits_list, dim=1)\n",
    "#         pad_len = self.max_len - output.size(1)\n",
    "#         if pad_len > 0:\n",
    "#             pad_logits = torch.full((batch_size, pad_len, self.vocab_size), float('-inf'), device=feats.device)\n",
    "#             pad_logits[:, :, self.pad_tkn_idx] = 0\n",
    "#             output = torch.cat([output, pad_logits], dim=1)\n",
    "    \n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461e35e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.533381Z",
     "iopub.status.busy": "2025-05-25T18:17:57.533161Z",
     "iopub.status.idle": "2025-05-25T18:17:57.538186Z",
     "shell.execute_reply": "2025-05-25T18:17:57.537517Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015847,
     "end_time": "2025-05-25T18:17:57.539310",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.523463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import timm\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class ChildSumTreeLSTMCell(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.child_num = max_len\n",
    "\n",
    "#         self.W_i = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_f = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_o = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "#         self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "#         self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "#         self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "#     def forward(self, x, child_h, child_c):\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "#         zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "#         zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "#         actual_len = len(child_h)\n",
    "#         child_h = child_h + [zero_h] * (self.child_num - actual_len)\n",
    "#         child_c = child_c + [zero_c] * (self.child_num - actual_len)\n",
    "\n",
    "#         i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(actual_len)) + self.b_i\n",
    "#         o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(actual_len)) + self.b_o\n",
    "#         u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(actual_len)) + self.b_u\n",
    "\n",
    "#         i = torch.sigmoid(i_input)\n",
    "#         o = torch.sigmoid(o_input)\n",
    "#         u = torch.tanh(u_input)\n",
    "\n",
    "#         c = i * u\n",
    "#         for k in range(actual_len):\n",
    "#             f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "#             c += f_k * child_c[k]\n",
    "\n",
    "#         h = o * torch.tanh(c)\n",
    "#         return h, c\n",
    "\n",
    "\n",
    "# class FathomnetClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.stop_tkn_idx = stop_tkn_idx\n",
    "#         self.pad_tkn_idx = pad_tkn_idx\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#         # EfficientNet backbone\n",
    "#         backbone = timm.create_model(\"resnest269e\", pretrained=True, num_classes=0)  # num_classes=0 disables classifier\n",
    "#         self.feature_extractor = nn.Sequential(\n",
    "#             backbone,  # full model will just return features\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "#         feat_dim = backbone.num_features  # e.g., 1280 for B0\n",
    "\n",
    "#         self.img_proj = nn.Linear(feat_dim, hidden_size)\n",
    "\n",
    "#         # Token embedding\n",
    "#         self.token_emb = nn.Embedding(vocab_size, hidden_size)\n",
    "#         self.start_token = nn.Parameter(torch.randn(1, hidden_size))\n",
    "\n",
    "#         # TreeLSTM\n",
    "#         self.tree_cell = ChildSumTreeLSTMCell(input_size=hidden_size, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "#         # Classifier\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "#         self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x, targets=None):\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "\n",
    "#         # 1. Encode image\n",
    "#         feats = self.feature_extractor(x)  # [B, feat_dim]\n",
    "#         img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "#         img_c = torch.zeros_like(img_h)\n",
    "\n",
    "#         hidden_states = [img_h]\n",
    "#         cell_states = [img_c]\n",
    "#         logits_list = []\n",
    "\n",
    "#         done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "#         current_token = self.start_token.expand(batch_size, -1)\n",
    "\n",
    "#         for t in range(self.max_len):\n",
    "#             h_t, c_t = self.tree_cell(current_token, hidden_states, cell_states)\n",
    "#             hidden_states.append(h_t)\n",
    "#             cell_states.append(c_t)\n",
    "\n",
    "#             logits = self.fc(h_t)  # [B, V]\n",
    "#             logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "#             if targets is not None:\n",
    "#                 # Teacher forcing\n",
    "#                 current_token = self.token_emb(targets[:, t])\n",
    "#             else:\n",
    "#                 # Inference\n",
    "#                 preds = torch.argmax(logits, dim=1)\n",
    "#                 done |= (preds == self.stop_tkn_idx)\n",
    "#                 current_token = self.token_emb(preds)\n",
    "#                 if done.all():\n",
    "#                     break\n",
    "\n",
    "#         output = torch.cat(logits_list, dim=1)\n",
    "\n",
    "#         if targets is not None:\n",
    "#             loss = self.loss(output.view(-1, self.vocab_size), targets.view(-1))\n",
    "#             return output, loss\n",
    "\n",
    "#         # Pad if needed\n",
    "#         pad_len = self.max_len - output.size(1)\n",
    "#         if pad_len > 0:\n",
    "#             pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "#             pad_logits[:, :, self.pad_tkn_idx] = 1\n",
    "#             output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "#         return output  # [B, max_len, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d44459f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.604597Z",
     "iopub.status.busy": "2025-05-25T18:17:57.604337Z",
     "iopub.status.idle": "2025-05-25T18:17:57.620650Z",
     "shell.execute_reply": "2025-05-25T18:17:57.620107Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027498,
     "end_time": "2025-05-25T18:17:57.621663",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.594165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N-ary Tree LSTM\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import EfficientNet_V2_M_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "\n",
    "class ChildSumTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.child_num = max_len  # max number of children\n",
    "\n",
    "        # Input projections\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Distinct hidden projections per child (indexed by position)\n",
    "        self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "        # Bias terms\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, child_h, child_c):\n",
    "        # Pad child_h and child_c with zeros up to self.child_num\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        # Fill missing child states\n",
    "        child_h = child_h + [zero_h] * (self.child_num - len(child_h))\n",
    "        child_c = child_c + [zero_c] * (self.child_num - len(child_c))\n",
    "\n",
    "        # Sum over active children only (i.e., up to original len)\n",
    "        active_len = len(child_h) - (self.child_num - len(child_h))\n",
    "\n",
    "        # Gates\n",
    "        i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(active_len)) + self.b_i\n",
    "        o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(active_len)) + self.b_o\n",
    "        u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(active_len)) + self.b_u\n",
    "\n",
    "        i = torch.sigmoid(i_input)\n",
    "        o = torch.sigmoid(o_input)\n",
    "        u = torch.tanh(u_input)\n",
    "\n",
    "        # Forget gates and new cell state\n",
    "        c = i * u\n",
    "        for k in range(active_len):\n",
    "            f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "            c += f_k * child_c[k]\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class FathomnetClassTree(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn_idx = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # EfficientNet feature extractor\n",
    "        base = models.efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        # base = convnext_base(weights=ConvNeXt_Base_Weights.DEFAULT)\n",
    "        base = model\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            base.features,\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Project image features to LSTM hidden size\n",
    "        self.img_proj = nn.Linear(input_dim, hidden_size)\n",
    "\n",
    "        # TreeLSTM cell (shared across time)\n",
    "        self.tree_cell = ChildSumTreeLSTMCell(input_size=input_dim, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "        # Final classifier head\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "\n",
    "        # 1. Extract image features\n",
    "        feats = self.feature_extractor(x)  # [B, input_dim]\n",
    "        img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "        img_c = torch.zeros_like(img_h)\n",
    "\n",
    "        # 2. Init state\n",
    "        hidden_states = [img_h]\n",
    "        cell_states = [img_c]\n",
    "        logits_list = []\n",
    "\n",
    "        done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        # 3. Decode for max_len steps\n",
    "        for t in range(self.max_len):\n",
    "            h_t, c_t = self.tree_cell(feats, hidden_states, cell_states)\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "\n",
    "            logits = self.fc(h_t)  # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            done |= (preds == self.stop_tkn_idx)\n",
    "            if done.all():\n",
    "                break\n",
    "\n",
    "        # 4. Padding if needed\n",
    "        output = torch.cat(logits_list, dim=1)\n",
    "        pad_len = self.max_len - output.size(1)\n",
    "        if pad_len > 0:\n",
    "            pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, self.pad_tkn_idx] = 1  # Add one-hot pad probs\n",
    "            output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "        return output  # [B, max_len, vocab_size]\n",
    "\n",
    "    def criterion(self, x, y):\n",
    "        logits = self.forward(x)                   # [B, 7, V]\n",
    "        y = y.float()                              # [B, 7, V]\n",
    "        logits_flat = logits.view(-1, self.vocab_size)\n",
    "        targets_flat = y.view(-1, self.vocab_size)\n",
    "        return self.loss(logits_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b44973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.641555Z",
     "iopub.status.busy": "2025-05-25T18:17:57.641333Z",
     "iopub.status.idle": "2025-05-25T18:17:57.645116Z",
     "shell.execute_reply": "2025-05-25T18:17:57.644576Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015052,
     "end_time": "2025-05-25T18:17:57.646115",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.631063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Normal LSTM\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models\n",
    "# from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "\n",
    "# class FathomnetClassLSTM(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "#         super().__init__()\n",
    "#         # Feature extractor\n",
    "#         # self.model = models.efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "#         self.model = convnext_base(weights=ConvNeXt_Base_Weights.DEFAULT)\n",
    "#         self.feature_extractor = nn.Sequential(\n",
    "#             self.model.features,\n",
    "#             nn.AdaptiveAvgPool2d((1,1)),\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "\n",
    "#         # GRU decoder (changed from LSTM to GRU)\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "#         # Direct index assignment from known tensors\n",
    "#         self.stop_tkn_idx = stop_tkn_idx\n",
    "#         self.pad_tkn = pad_tkn_idx\n",
    "#         self.max_len = max_len\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.lambda_path = 0.3\n",
    "\n",
    "#         # Loss function ignoring padding tokens\n",
    "#         self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, device = x.size(0), x.device\n",
    "#         feats = self.feature_extractor(x)              # [B, input_dim]\n",
    "#         input_seq = feats.unsqueeze(1)                 # [B, 1, input_dim]\n",
    "\n",
    "#         hidden = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "#         cell   = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "#         logits_list = []                               # [B, t, V]\n",
    "#         done = [False] * batch_size\n",
    "\n",
    "#         for t in range(self.max_len):\n",
    "#             out, (hidden, cell) = self.lstm(input_seq, (hidden, cell))  # [B,1,H]\n",
    "#             logits = self.fc(out.squeeze(1))                             # [B, V]\n",
    "#             logits_list.append(logits.unsqueeze(1))                      # [B,1,V]\n",
    "\n",
    "#             preds = torch.argmax(logits, dim=1)                          # [B]\n",
    "#             for i in range(batch_size):\n",
    "#                 if not done[i] and preds[i].item() == 5:\n",
    "#                     done[i] = True\n",
    "#             if all(done):\n",
    "#                 break\n",
    "\n",
    "#             input_seq = feats.unsqueeze(1)\n",
    "\n",
    "#         logits_tensor = torch.cat(logits_list, dim=1)  # [B, T_pred, V]; Here T-pred is varible <= 7\n",
    "#         # pad to max_len\n",
    "#         if logits_tensor.size(1) < self.max_len:\n",
    "#             pad_size = self.max_len - logits_tensor.size(1)\n",
    "#             pad_logits = torch.zeros(batch_size, pad_size, self.vocab_size, device=device)\n",
    "#             pad_logits[:, :, 6] = 1\n",
    "#             logits_tensor = torch.cat([logits_tensor, pad_logits], dim=1)\n",
    "\n",
    "#         return logits_tensor   #[B, 7, V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a614c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.665701Z",
     "iopub.status.busy": "2025-05-25T18:17:57.665444Z",
     "iopub.status.idle": "2025-05-25T18:17:57.669278Z",
     "shell.execute_reply": "2025-05-25T18:17:57.668583Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014905,
     "end_time": "2025-05-25T18:17:57.670313",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.655408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear Classifier\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# class FathomNetClassifier(nn.Module):\n",
    "#     \"\"\"\n",
    "#     A PyTorch module for classifying marine species using a pretrained EfficientNetV2-M model.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(FathomNetClassifier, self).__init__()\n",
    "        \n",
    "#         # Load pretrained EfficientNetV2-M backbone\n",
    "#         self.backbone = models.efficientnet_v2_m(weights=models.EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        \n",
    "#         # Replace the classifier head\n",
    "#         in_features = self.backbone.classifier[1].in_features\n",
    "#         self.backbone.classifier = nn.Sequential(\n",
    "#             nn.Linear(in_features, 48),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.15),\n",
    "#             nn.Linear(48, num_classes)\n",
    "#         )\n",
    "#         # Loss function\n",
    "#         self.loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Forward pass.\"\"\"\n",
    "#         return self.backbone(x)\n",
    "\n",
    "#     def compute_loss(self, x, labels):\n",
    "#         \"\"\"Returns loss and logits.\"\"\"\n",
    "#         logits = self.forward(x)\n",
    "#         loss = self.loss_fn(logits, labels)\n",
    "#         return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bf13be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.692423Z",
     "iopub.status.busy": "2025-05-25T18:17:57.692159Z",
     "iopub.status.idle": "2025-05-25T18:17:57.708055Z",
     "shell.execute_reply": "2025-05-25T18:17:57.707339Z"
    },
    "papermill": {
     "duration": 0.029438,
     "end_time": "2025-05-25T18:17:57.709148",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.679710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Swin Transformer Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import timm  # for ResNeST backbone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # for progress bars\n",
    "\n",
    "\n",
    "class ChildSumTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.child_num = max_len\n",
    "\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_u = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.U_i = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_f = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_o = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "        self.U_u = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(max_len)])\n",
    "\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, child_h, child_c):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "        zero_h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        zero_c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        actual_len = len(child_h)\n",
    "        child_h = child_h + [zero_h] * (self.child_num - actual_len)\n",
    "        child_c = child_c + [zero_c] * (self.child_num - actual_len)\n",
    "\n",
    "        i_input = self.W_i(x) + sum(self.U_i[k](child_h[k]) for k in range(actual_len)) + self.b_i\n",
    "        o_input = self.W_o(x) + sum(self.U_o[k](child_h[k]) for k in range(actual_len)) + self.b_o\n",
    "        u_input = self.W_u(x) + sum(self.U_u[k](child_h[k]) for k in range(actual_len)) + self.b_u\n",
    "\n",
    "        i = torch.sigmoid(i_input)\n",
    "        o = torch.sigmoid(o_input)\n",
    "        u = torch.tanh(u_input)\n",
    "\n",
    "        c = i * u\n",
    "        for k in range(actual_len):\n",
    "            f_k = torch.sigmoid(self.W_f(x) + self.U_f[k](child_h[k]) + self.b_f)\n",
    "            c += f_k * child_c[k]\n",
    "\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class FathomnetClassSwin(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, vocab_size, stop_tkn_idx, pad_tkn_idx, max_len):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stop_tkn_idx = stop_tkn_idx\n",
    "        self.pad_tkn_idx = pad_tkn_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # EfficientNet backbone\n",
    "        backbone = timm.create_model(\"swin_large_patch4_window7_224\", pretrained=True, num_classes=0)  # num_classes=0 disables classifier\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            backbone,  # full model will just return features\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        feat_dim = backbone.num_features    # [batch_size, 1536]\n",
    "\n",
    "        self.img_proj = nn.Linear(feat_dim, hidden_size)\n",
    "\n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.start_token = nn.Parameter(torch.randn(1, hidden_size))\n",
    "\n",
    "        # TreeLSTM\n",
    "        self.tree_cell = ChildSumTreeLSTMCell(input_size=hidden_size, hidden_size=hidden_size, max_len=max_len)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        batch_size, device = x.size(0), x.device\n",
    "\n",
    "        # 1. Encode image\n",
    "        feats = self.feature_extractor(x)  # [B, feat_dim]\n",
    "        img_h = torch.tanh(self.img_proj(feats))  # [B, H]\n",
    "        img_c = torch.zeros_like(img_h)\n",
    "\n",
    "        hidden_states = [img_h]\n",
    "        cell_states = [img_c]\n",
    "        logits_list = []\n",
    "\n",
    "        done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        current_token = self.start_token.expand(batch_size, -1)\n",
    "\n",
    "        for t in range(self.max_len):\n",
    "            h_t, c_t = self.tree_cell(current_token, hidden_states, cell_states)\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "\n",
    "            logits = self.fc(h_t)  # [B, V]\n",
    "            logits_list.append(logits.unsqueeze(1))\n",
    "\n",
    "            if targets is not None:\n",
    "                # Teacher forcing\n",
    "                current_token = self.token_emb(targets[:, t])\n",
    "            else:\n",
    "                # Inference\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                done |= (preds == self.stop_tkn_idx)\n",
    "                current_token = self.token_emb(preds)\n",
    "                if done.all():\n",
    "                    break\n",
    "\n",
    "        output = torch.cat(logits_list, dim=1)\n",
    "\n",
    "        if targets is not None:\n",
    "            loss = self.loss(output.view(-1, self.vocab_size), targets.view(-1))\n",
    "            return output, loss\n",
    "\n",
    "        # Pad if needed\n",
    "        pad_len = self.max_len - output.size(1)\n",
    "        if pad_len > 0:\n",
    "            pad_logits = torch.zeros(batch_size, pad_len, self.vocab_size, device=device)\n",
    "            pad_logits[:, :, self.pad_tkn_idx] = 1\n",
    "            output = torch.cat([output, pad_logits], dim=1)\n",
    "\n",
    "        return output  # [B, max_len, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c5d7728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.728287Z",
     "iopub.status.busy": "2025-05-25T18:17:57.727735Z",
     "iopub.status.idle": "2025-05-25T18:17:57.731612Z",
     "shell.execute_reply": "2025-05-25T18:17:57.730921Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014503,
     "end_time": "2025-05-25T18:17:57.732666",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.718163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import models\n",
    "\n",
    "\n",
    "# class FathomClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes, model_train=False):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Load pretrained MobileNetV3 Large\n",
    "#         mobilenet = models.mobilenet_v3_large(pretrained=True)\n",
    "#         self.feature_extractor = mobilenet.features  # Remove classifier head\n",
    "#         self.pool = nn.AdaptiveAvgPool2d((1, 1))     # Mimic global pooling\n",
    "#         self.flatten = nn.Flatten()\n",
    "        \n",
    "#         encoder_output_dim = mobilenet.classifier[0].in_features  # usually 960\n",
    "\n",
    "#         if not model_train:\n",
    "#             for param in self.feature_extractor.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(encoder_output_dim, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, num_classes)\n",
    "#         )\n",
    "\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.flatten(x)\n",
    "#         return self.classifier(x)\n",
    "\n",
    "#     def compute_loss(self, x, y):\n",
    "#         logits = self.forward(x)\n",
    "#         loss = self.criterion(logits, y)\n",
    "#         return loss, logits\n",
    "\n",
    "\n",
    "# def get_optimizer_and_scheduler(model, monitor='val_loss'):\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer,\n",
    "#         mode=\"min\",\n",
    "#         factor=0.5,\n",
    "#         patience=3,\n",
    "#         verbose=True,\n",
    "#         min_lr=1e-6\n",
    "#     )\n",
    "#     return optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "976aeacf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.751490Z",
     "iopub.status.busy": "2025-05-25T18:17:57.751276Z",
     "iopub.status.idle": "2025-05-25T18:17:57.755159Z",
     "shell.execute_reply": "2025-05-25T18:17:57.754486Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014503,
     "end_time": "2025-05-25T18:17:57.756223",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.741720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Input Encdoded Through model\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "\n",
    "# class FathomClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes, model, encoder_output_dim=512, model_train = False):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.tokenizer = open_clip.get_tokenizer('hf-hub:imageomics/bioclip')\n",
    "\n",
    "#         if model_train is False:\n",
    "#             for param in self.model.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#         # self.classifier = nn.Sequential(\n",
    "#         #     nn.Linear(encoder_output_dim, num_classes)\n",
    "#         # )\n",
    "\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(encoder_output_dim, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, num_classes)\n",
    "#         )\n",
    "\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.model(x)[0]\n",
    "#         return self.classifier(features)\n",
    "\n",
    "\n",
    "#     def compute_loss(self, x, y):\n",
    "#         \"\"\"Compute loss given input images and ground truth labels.\"\"\"\n",
    "#         logits = self.forward(x)\n",
    "#         loss = self.criterion(logits, y)\n",
    "#         return loss, logits\n",
    "\n",
    "\n",
    "# def get_optimizer_and_scheduler(model, monitor='val_loss'):\n",
    "#     \"\"\"\n",
    "#     Returns optimizer and scheduler like PyTorch Lightning.\n",
    "#     \"\"\"\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#             optimizer,\n",
    "#             mode='min',\n",
    "#             factor=0.5,\n",
    "#             patience=3,\n",
    "#             verbose=True,\n",
    "#             min_lr=1e-6,\n",
    "#             threshold=0.03,\n",
    "#             threshold_mode='rel'\n",
    "#         )\n",
    "#     return optimizer, scheduler        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08e3783d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.774646Z",
     "iopub.status.busy": "2025-05-25T18:17:57.774468Z",
     "iopub.status.idle": "2025-05-25T18:17:57.777589Z",
     "shell.execute_reply": "2025-05-25T18:17:57.776932Z"
    },
    "papermill": {
     "duration": 0.013515,
     "end_time": "2025-05-25T18:17:57.778657",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.765142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# train_annotations_df = pd.read_csv(\"/kaggle/input/fathomnet-dataset/annotations_Train (1).csv\")\n",
    "# label_encoder = LabelEncoder().fit(train_annotations_df[\"label\"].dropna())\n",
    "# train_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92d0e1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.797153Z",
     "iopub.status.busy": "2025-05-25T18:17:57.796976Z",
     "iopub.status.idle": "2025-05-25T18:17:57.800050Z",
     "shell.execute_reply": "2025-05-25T18:17:57.799398Z"
    },
    "papermill": {
     "duration": 0.013735,
     "end_time": "2025-05-25T18:17:57.801181",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.787446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model = FathomNetClassifier(num_classes=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b4db405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.820957Z",
     "iopub.status.busy": "2025-05-25T18:17:57.820477Z",
     "iopub.status.idle": "2025-05-25T18:17:57.823434Z",
     "shell.execute_reply": "2025-05-25T18:17:57.822929Z"
    },
    "papermill": {
     "duration": 0.014465,
     "end_time": "2025-05-25T18:17:57.824458",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.809993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FathomnetClass(input_dim = 2048, hidden_size = 1024, vocab_size = 151, stop_tkn_idx = torch.argmax(torch.tensor(onehot['spl_stp'])).item(), pad_tkn_idx = torch.argmax(torch.tensor(onehot['-'])).item(), max_len = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80248579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:17:57.843218Z",
     "iopub.status.busy": "2025-05-25T18:17:57.842792Z",
     "iopub.status.idle": "2025-05-25T18:18:04.119785Z",
     "shell.execute_reply": "2025-05-25T18:18:04.119212Z"
    },
    "papermill": {
     "duration": 6.287846,
     "end_time": "2025-05-25T18:18:04.121244",
     "exception": false,
     "start_time": "2025-05-25T18:17:57.833398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b678ed16ed49068a3841e281cfca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/788M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FathomnetClassSwin(input_dim=1536, hidden_size=512, vocab_size=151,\n",
    "                                 stop_tkn_idx=torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "                                 pad_tkn_idx=torch.argmax(torch.tensor(onehot['-'])).item(), max_len=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7f823d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:04.142092Z",
     "iopub.status.busy": "2025-05-25T18:18:04.141814Z",
     "iopub.status.idle": "2025-05-25T18:18:18.208541Z",
     "shell.execute_reply": "2025-05-25T18:18:18.207777Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 14.078436,
     "end_time": "2025-05-25T18:18:18.209795",
     "exception": false,
     "start_time": "2025-05-25T18:18:04.131359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1567333686.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load('/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FathomnetClassSwin(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): SwinTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): SwinTransformerStage(\n",
       "          (downsample): Identity()\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.004)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.004)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.009)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.009)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.013)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.013)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.017)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.017)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.022)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.022)\n",
       "            )\n",
       "            (2): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.026)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.026)\n",
       "            )\n",
       "            (3): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.030)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.030)\n",
       "            )\n",
       "            (4): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.035)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.035)\n",
       "            )\n",
       "            (5): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.039)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.039)\n",
       "            )\n",
       "            (6): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.043)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.043)\n",
       "            )\n",
       "            (7): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.048)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.048)\n",
       "            )\n",
       "            (8): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.052)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.052)\n",
       "            )\n",
       "            (9): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.057)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.057)\n",
       "            )\n",
       "            (10): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.061)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.061)\n",
       "            )\n",
       "            (11): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.065)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.065)\n",
       "            )\n",
       "            (12): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.070)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.070)\n",
       "            )\n",
       "            (13): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.074)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.074)\n",
       "            )\n",
       "            (14): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.078)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.078)\n",
       "            )\n",
       "            (15): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.083)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.083)\n",
       "            )\n",
       "            (16): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.087)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.087)\n",
       "            )\n",
       "            (17): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.091)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.091)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.096)\n",
       "              (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.096)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.100)\n",
       "              (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.100)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): ClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Identity()\n",
       "        (flatten): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (img_proj): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (token_emb): Embedding(151, 512)\n",
       "  (tree_cell): ChildSumTreeLSTMCell(\n",
       "    (W_i): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (W_f): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (W_u): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (U_i): ModuleList(\n",
       "      (0-6): 7 x Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "    (U_f): ModuleList(\n",
       "      (0-6): 7 x Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "    (U_o): ModuleList(\n",
       "      (0-6): 7 x Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "    (U_u): ModuleList(\n",
       "      (0-6): 7 x Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=151, bias=True)\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ckpt = torch.load('/kaggle/input/retrained-models/swin/swin_trans_treelstm_ens_4o_complete.pth', map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95ac6c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.230764Z",
     "iopub.status.busy": "2025-05-25T18:18:18.230531Z",
     "iopub.status.idle": "2025-05-25T18:18:18.233516Z",
     "shell.execute_reply": "2025-05-25T18:18:18.233014Z"
    },
    "papermill": {
     "duration": 0.014385,
     "end_time": "2025-05-25T18:18:18.234450",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.220065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for param in model.feature_extractor.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3136b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.255503Z",
     "iopub.status.busy": "2025-05-25T18:18:18.254821Z",
     "iopub.status.idle": "2025-05-25T18:18:18.258303Z",
     "shell.execute_reply": "2025-05-25T18:18:18.257733Z"
    },
    "papermill": {
     "duration": 0.015342,
     "end_time": "2025-05-25T18:18:18.259375",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.244033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Load and transform the test dataset\n",
    "# test_dataset = FathomNetDataset_tkn(csv_path=\"/kaggle/input/fathomnet-dataset/annotations_Test.csv\", transform=test_transforms, is_test=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdb4613f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.280000Z",
     "iopub.status.busy": "2025-05-25T18:18:18.279781Z",
     "iopub.status.idle": "2025-05-25T18:18:18.282858Z",
     "shell.execute_reply": "2025-05-25T18:18:18.282386Z"
    },
    "papermill": {
     "duration": 0.014816,
     "end_time": "2025-05-25T18:18:18.284010",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.269194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Instantiate the model\n",
    "# num_classes = len(label_encoder.classes_)\n",
    "# best_model = FathomNetClassifier(num_classes=num_classes)\n",
    "\n",
    "# # Load the checkpoint and restore model weights\n",
    "# checkpoint = torch.load(\"/kaggle/input/lstm_v1/pytorch/linear/1/Linear_2.pth\", map_location=device)\n",
    "# best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# best_model = best_model.to(device)\n",
    "# best_model.eval()\n",
    "\n",
    "# # Run inference with progress bar\n",
    "# predictions = []\n",
    "# ids = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_loader, desc=\"Predicting\", leave=False):\n",
    "#         images, image_ids = batch\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         logits = best_model(images)\n",
    "#         preds = torch.argmax(logits, dim=1).tolist()\n",
    "#         predictions.extend(preds)\n",
    "#         ids.extend(image_ids)\n",
    "\n",
    "# # Decode numeric predictions to original string labels\n",
    "# decoded_predictions = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b2458c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.304513Z",
     "iopub.status.busy": "2025-05-25T18:18:18.304311Z",
     "iopub.status.idle": "2025-05-25T18:18:18.307179Z",
     "shell.execute_reply": "2025-05-25T18:18:18.306679Z"
    },
    "papermill": {
     "duration": 0.014221,
     "end_time": "2025-05-25T18:18:18.308157",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.293936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save predictions to the test annotations CSV file\n",
    "# submission_df = pd.read_csv(\"/kaggle/input/fathomnet-dataset/annotations_Test.csv\")\n",
    "# submission_df[\"annotation_id\"] = range(1, len(submission_df) + 1)\n",
    "# submission_df[\"concept_name\"] = decoded_predictions\n",
    "# submission_df = submission_df.drop([\"path\", \"label\"], axis=1)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)\n",
    "# submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "071b353d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.328253Z",
     "iopub.status.busy": "2025-05-25T18:18:18.328047Z",
     "iopub.status.idle": "2025-05-25T18:18:18.331045Z",
     "shell.execute_reply": "2025-05-25T18:18:18.330388Z"
    },
    "papermill": {
     "duration": 0.014354,
     "end_time": "2025-05-25T18:18:18.332144",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.317790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Initialize the model with the correct number of classes\n",
    "# # model = FathomClassifier(num_classes=len(id_to_name), model = vit, model_train = False)\n",
    "# # model = FathomClassifier(num_classes=len(id_to_name), model_train = False)\n",
    "# model = FathomnetClass(input_dim = 1280, hidden_size = 512, vocab_size = 151, stop_tkn_idx = torch.argmax(torch.tensor(onehot['spl_stp'])).item(), pad_tkn_idx = torch.argmax(torch.tensor(onehot['-'])).item(), max_len = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a925c7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.352254Z",
     "iopub.status.busy": "2025-05-25T18:18:18.352057Z",
     "iopub.status.idle": "2025-05-25T18:18:18.355098Z",
     "shell.execute_reply": "2025-05-25T18:18:18.354556Z"
    },
    "papermill": {
     "duration": 0.01444,
     "end_time": "2025-05-25T18:18:18.356253",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.341813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# check = torch.load('/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/4/TreeLSTM_Nary_512_6o.pth')\n",
    "# model.load_state_dict(check['model_state_dict'])\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abdb0b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.376234Z",
     "iopub.status.busy": "2025-05-25T18:18:18.376034Z",
     "iopub.status.idle": "2025-05-25T18:18:18.379105Z",
     "shell.execute_reply": "2025-05-25T18:18:18.378461Z"
    },
    "papermill": {
     "duration": 0.014266,
     "end_time": "2025-05-25T18:18:18.380230",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.365964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Freeze all parameters\n",
    "# # for param in model.parameters():\n",
    "# #     param.requires_grad = False\n",
    "\n",
    "# # # Unfreeze classifier parameters\n",
    "# # for param in model.classifier.parameters():\n",
    "# #     param.requires_grad = False\n",
    "\n",
    "# for param in model.feature_extractor.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bd927d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.400727Z",
     "iopub.status.busy": "2025-05-25T18:18:18.400542Z",
     "iopub.status.idle": "2025-05-25T18:18:18.403397Z",
     "shell.execute_reply": "2025-05-25T18:18:18.402938Z"
    },
    "papermill": {
     "duration": 0.014297,
     "end_time": "2025-05-25T18:18:18.404375",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.390078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Load and transform the test dataset\n",
    "# test_dataset = FathomNetDataset(csv_path='../../Test/annotations.csv', transformation=preprocess_val, label_encoder=None, is_test=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7418c2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.425265Z",
     "iopub.status.busy": "2025-05-25T18:18:18.424597Z",
     "iopub.status.idle": "2025-05-25T18:18:18.428031Z",
     "shell.execute_reply": "2025-05-25T18:18:18.427367Z"
    },
    "papermill": {
     "duration": 0.015003,
     "end_time": "2025-05-25T18:18:18.429208",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.414205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# df = pd.read_csv(\"/kaggle/input/fathomnet-dataset/annotations_Test_v1.csv\")\n",
    "# original_base_path = \"/kaggle/input/fathomnet-dataset/DataSet/DataSet/Test_imgs/rois\"\n",
    "# df['path'] = df['path'].apply(lambda x: os.path.join(original_base_path, x.replace(\"\\\\\", \"/\").split(\"/\")[-1]))\n",
    "# df.to_csv(\"/kaggle/working/annotations_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88faf66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.450128Z",
     "iopub.status.busy": "2025-05-25T18:18:18.449438Z",
     "iopub.status.idle": "2025-05-25T18:18:18.465933Z",
     "shell.execute_reply": "2025-05-25T18:18:18.465154Z"
    },
    "papermill": {
     "duration": 0.028008,
     "end_time": "2025-05-25T18:18:18.467133",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.439125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "from torch.utils.data import DataLoader\n",
    "test_dataset = FathomNetDataset_tkn(\n",
    "    csv_path='/kaggle/input/fathomnet-dataset/annotations_Test.csv',\n",
    "    transformation=test_transforms,\n",
    "    is_test=True\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff1f1b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.488404Z",
     "iopub.status.busy": "2025-05-25T18:18:18.488163Z",
     "iopub.status.idle": "2025-05-25T18:18:18.491381Z",
     "shell.execute_reply": "2025-05-25T18:18:18.490706Z"
    },
    "papermill": {
     "duration": 0.015063,
     "end_time": "2025-05-25T18:18:18.492489",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.477426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check = torch.load('/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/4/TreeLSTM_Nary_512_3.pth')\n",
    "# check['model_state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea46b333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:18.512737Z",
     "iopub.status.busy": "2025-05-25T18:18:18.512549Z",
     "iopub.status.idle": "2025-05-25T18:18:19.554244Z",
     "shell.execute_reply": "2025-05-25T18:18:19.553494Z"
    },
    "papermill": {
     "duration": 1.053292,
     "end_time": "2025-05-25T18:18:19.555629",
     "exception": false,
     "start_time": "2025-05-25T18:18:18.502337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 151])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "input_tensor = test_dataset[0][0].unsqueeze(0).to(device)\n",
    "model.eval()  # <-- Add this line before inference\n",
    "logits = model(input_tensor)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "150c9d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:19.577584Z",
     "iopub.status.busy": "2025-05-25T18:18:19.577352Z",
     "iopub.status.idle": "2025-05-25T18:18:19.582927Z",
     "shell.execute_reply": "2025-05-25T18:18:19.582239Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01752,
     "end_time": "2025-05-25T18:18:19.583998",
     "exception": false,
     "start_time": "2025-05-25T18:18:19.566478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Assume FathomnetClass is defined/imported above\n",
    "\n",
    "# def load_models(weight_path1, weight_path2, **model_kwargs):\n",
    "#     \"\"\"\n",
    "#     Load two FathomnetClass models from checkpoint dicts and set them to eval mode.\n",
    "#     \"\"\"\n",
    "#     model1 = FathomnetClassLSTM(**model_kwargs)\n",
    "#     model2 = FathomnetClassTree(**model_kwargs)\n",
    "\n",
    "#     ckpt1 = torch.load(weight_path1, map_location='cpu')\n",
    "#     ckpt2 = torch.load(weight_path2, map_location='cpu')\n",
    "\n",
    "#     model1.load_state_dict(ckpt1['model_state_dict'])\n",
    "#     model2.load_state_dict(ckpt2['model_state_dict'])\n",
    "\n",
    "#     model1.eval()\n",
    "#     model2.eval()\n",
    "#     return model1, model2\n",
    "\n",
    "\n",
    "# # def ensemble_predict(models, x):\n",
    "# #     \"\"\"\n",
    "# #     Run input tensor through both models, average their logits, and return predicted indices.\n",
    "\n",
    "# #     Args:\n",
    "# #         models: list of two nn.Modules\n",
    "# #         x: input batch [B, C, H, W]\n",
    "# #     Returns:\n",
    "# #         Tensor of shape [B, T] with token predictions\n",
    "# #     \"\"\"\n",
    "# #     logits1 = models[0](x)\n",
    "# #     logits2 = models[1](x)\n",
    "# #     combined = (4.2*logits1 + 5.8*logits2) / 10\n",
    "# #     preds = combined.argmax(dim=-1)\n",
    "# #     return preds\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def ensemble_predict(models, image_batch):\n",
    "#     \"\"\"\n",
    "#     Ensemble prediction from 2 sequence models (Tree/LSTM) and 1 classifier model.\n",
    "    \n",
    "#     Args:\n",
    "#         models: [model1, model2, model3]\n",
    "#             - model1, model2: TreeLSTM / LSTM  return logits for tokens\n",
    "#             - model3: EfficientNet  returns logits for classes directly\n",
    "#         image_batch: torch.Tensor of shape [B, C, H, W]\n",
    "    \n",
    "#     Returns:\n",
    "#         final_preds: Tensor of shape [B] with predicted class indices\n",
    "#     \"\"\"\n",
    "#     # First two models return logits over token sequences\n",
    "#     logits1 = models[0](image_batch)\n",
    "#     logits2 = models[1](image_batch)\n",
    "    \n",
    "#     # Apply weighted average to sequence-level logits\n",
    "#     seq_logits = (4.2 * logits1 + 5.8 * logits2) / 10\n",
    "#     seq_preds = seq_logits.argmax(dim=-1)  # [B, T]\n",
    "\n",
    "#     # You likely use only the first token (e.g., root node class) as final prediction\n",
    "#     root_preds = seq_preds[:, 0]  # [B]\n",
    "\n",
    "#     # Third model is a direct classifier\n",
    "#     logits3 = models[2](image_batch)\n",
    "#     logits3 = label_encoder.inverse_transform(logits3)\n",
    "#     cls_preds = logits3.argmax(dim=-1)  # [B]\n",
    "\n",
    "#     # Combine root_preds and cls_preds using majority vote\n",
    "#     final_preds = []\n",
    "#     for r, c in zip(root_preds.tolist(), cls_preds.tolist()):\n",
    "#         votes = [r, c]  # Add model 3's vote\n",
    "#         final_preds.append(max(set(votes), key=votes.count))  # majority vote\n",
    "\n",
    "#     return torch.tensor(final_preds)\n",
    "\n",
    "\n",
    "# # ---------------------- USAGE EXAMPLE ----------------------\n",
    "# # Model parameters\n",
    "# model_kwargs = {\n",
    "#     'input_dim': 1280,\n",
    "#     'hidden_size': 512,\n",
    "#     'vocab_size': 151,\n",
    "#     'stop_tkn_idx': torch.argmax(torch.tensor(onehot['spl_stp'])).item(),\n",
    "#     'pad_tkn_idx': torch.argmax(torch.tensor(onehot['-'])).item(),\n",
    "#     'max_len': 7\n",
    "# }\n",
    "\n",
    "# # Paths to weights\n",
    "# weight1 = '/kaggle/input/lstm_v1/pytorch/v1/5/LSTM_3k_4.pth'\n",
    "# weight2 = '/kaggle/input/lstm_v1/pytorch/n-ary_treelstm/4/TreeLSTM_Nary_512_6o.pth'\n",
    "\n",
    "# # Load ensemble\n",
    "# model1, model2 = load_models(weight1, weight2, **model_kwargs)\n",
    "# ensemble_models = [model1, model2]\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for m in ensemble_models:\n",
    "#     m.to(device)\n",
    "\n",
    "# # Define helper to extract ID from filename\n",
    "# extract_after_underscore = lambda x: int(x.split('/')[-1].split('_')[1].split('.')[0])\n",
    "\n",
    "# # Containers for results\n",
    "# predictions = []\n",
    "# ids = []\n",
    "\n",
    "# # Inference over test data\n",
    "# for batch in tqdm(test_loader, desc=\"Processing batches\"):\n",
    "#     images, paths = batch  # assume loader returns (image, file_path)\n",
    "#     images = images.to(device)\n",
    "\n",
    "#     # Ensemble prediction\n",
    "#     batch_preds = ensemble_predict(ensemble_models, images)  # [B, T]\n",
    "\n",
    "#     # Move to CPU and convert to list\n",
    "#     preds_list = batch_preds.cpu().tolist()\n",
    "#     predictions.extend(preds_list)\n",
    "\n",
    "#     # Extract IDs\n",
    "#     batch_ids = [extract_after_underscore(p) for p in paths]\n",
    "#     ids.extend(batch_ids)\n",
    "\n",
    "# # Example: inspect first prediction\n",
    "# print(f\"Total samples: {len(ids)}\")\n",
    "# print(f\"First ID: {ids[0]}, First prediction: {predictions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f33f13a4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:19.604329Z",
     "iopub.status.busy": "2025-05-25T18:18:19.604109Z",
     "iopub.status.idle": "2025-05-25T18:18:34.880789Z",
     "shell.execute_reply": "2025-05-25T18:18:34.880074Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 15.288141,
     "end_time": "2025-05-25T18:18:34.882040",
     "exception": false,
     "start_time": "2025-05-25T18:18:19.593899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|| 25/25 [00:15<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "extract_after_underscore = lambda x: int(x.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0])\n",
    "predictions = []\n",
    "ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Processing batches\"):\n",
    "        image, lbls = batch\n",
    "        image = image.to(device)\n",
    "        out = model(image)\n",
    "        preds = out.argmax(dim=2).tolist()\n",
    "        predictions.extend(preds)\n",
    "        ids.extend([extract_after_underscore(path) for path in lbls])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1e10946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:34.906490Z",
     "iopub.status.busy": "2025-05-25T18:18:34.906244Z",
     "iopub.status.idle": "2025-05-25T18:18:34.913558Z",
     "shell.execute_reply": "2025-05-25T18:18:34.913004Z"
    },
    "papermill": {
     "duration": 0.020511,
     "end_time": "2025-05-25T18:18:34.914608",
     "exception": false,
     "start_time": "2025-05-25T18:18:34.894097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_idx = []\n",
    "for seq in predictions:\n",
    "    # 1) find cutoff index (first 5 or 6)\n",
    "    cutoff = next((i for i, x in enumerate(seq) if x in (5, 6)), len(seq))\n",
    "    prefix = seq[:cutoff]\n",
    "    \n",
    "    # 2) find last element in prefix that is also in labels_idx\n",
    "    found = next((x for x in reversed(prefix) if x in labels_idx), 0)\n",
    "    \n",
    "    pred_idx.append(found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf0c528a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:34.937651Z",
     "iopub.status.busy": "2025-05-25T18:18:34.937428Z",
     "iopub.status.idle": "2025-05-25T18:18:34.942056Z",
     "shell.execute_reply": "2025-05-25T18:18:34.941272Z"
    },
    "papermill": {
     "duration": 0.017331,
     "end_time": "2025-05-25T18:18:34.943261",
     "exception": false,
     "start_time": "2025-05-25T18:18:34.925930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "onehot_argmax = {v.values.argmax(): k for k, v in onehot.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1329c343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:34.967349Z",
     "iopub.status.busy": "2025-05-25T18:18:34.967159Z",
     "iopub.status.idle": "2025-05-25T18:18:34.970640Z",
     "shell.execute_reply": "2025-05-25T18:18:34.970092Z"
    },
    "papermill": {
     "duration": 0.016938,
     "end_time": "2025-05-25T18:18:34.971676",
     "exception": false,
     "start_time": "2025-05-25T18:18:34.954738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(pred_idx)):\n",
    "    preds.append(onehot_argmax[pred_idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a75431b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:34.996731Z",
     "iopub.status.busy": "2025-05-25T18:18:34.996169Z",
     "iopub.status.idle": "2025-05-25T18:18:35.007421Z",
     "shell.execute_reply": "2025-05-25T18:18:35.006712Z"
    },
    "papermill": {
     "duration": 0.024675,
     "end_time": "2025-05-25T18:18:35.008490",
     "exception": false,
     "start_time": "2025-05-25T18:18:34.983815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'concept_name':preds,\n",
    "    'annotation_id':ids\n",
    "})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddbaaaba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:18:35.031587Z",
     "iopub.status.busy": "2025-05-25T18:18:35.031402Z",
     "iopub.status.idle": "2025-05-25T18:18:35.050573Z",
     "shell.execute_reply": "2025-05-25T18:18:35.049952Z"
    },
    "papermill": {
     "duration": 0.032046,
     "end_time": "2025-05-25T18:18:35.051719",
     "exception": false,
     "start_time": "2025-05-25T18:18:35.019673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_name</th>\n",
       "      <th>annotation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elpidia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Funiculina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acanthoptilum</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acanthoptilum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acanthoptilum</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Asteroidea</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Tunicata</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Scotoplanes globosa</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Asteroidea</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Liponema brevicorne</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            concept_name  annotation_id\n",
       "0                Elpidia              1\n",
       "1             Funiculina              2\n",
       "2          Acanthoptilum              3\n",
       "3          Acanthoptilum              4\n",
       "4          Acanthoptilum              5\n",
       "..                   ...            ...\n",
       "783           Asteroidea            784\n",
       "784             Tunicata            785\n",
       "785  Scotoplanes globosa            786\n",
       "786           Asteroidea            787\n",
       "787  Liponema brevicorne            788\n",
       "\n",
       "[788 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.sort_values(by = 'annotation_id', ascending = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee2d62",
   "metadata": {
    "papermill": {
     "duration": 0.012194,
     "end_time": "2025-05-25T18:18:35.077300",
     "exception": false,
     "start_time": "2025-05-25T18:18:35.065106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11305476,
     "sourceId": 88612,
     "sourceType": "competition"
    },
    {
     "datasetId": 7125806,
     "sourceId": 11793354,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7434723,
     "sourceId": 11834096,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7485378,
     "sourceId": 11907216,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7499454,
     "sourceId": 11928705,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7512150,
     "sourceId": 11949070,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 309887,
     "modelInstanceId": 329218,
     "sourceId": 402511,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 355236,
     "modelInstanceId": 335639,
     "sourceId": 411100,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.477743,
   "end_time": "2025-05-25T18:18:38.519451",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T18:17:32.041708",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f22d207fc764e7aabad6167413639db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "27086f64ac574e68b141a17d64939d31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_34779ecdedaa42539f3b60eac7510cb0",
       "placeholder": "",
       "style": "IPY_MODEL_5dcfddc72087476ba762f422cc90a74f",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "34779ecdedaa42539f3b60eac7510cb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b4d5c6fbbbe448f91a348728faede2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d815abc77d54a4dbcbdcad5468c1bce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e52bcf5f2584d468da5f10a9fc5a299": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27086f64ac574e68b141a17d64939d31",
        "IPY_MODEL_7bb29e13c687446fa2c01fcdcc7f0dcf",
        "IPY_MODEL_89ed344fd1d94c8392c1f4605a0f22a0"
       ],
       "layout": "IPY_MODEL_a10435be735549c1ac1f2a215d6d549a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4c6ad99348394c64a8594b7ade8a4ad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4dfeaf7d052d409db10f670d3316ebb7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56316114593a4cc1b39ec4d2bf21340e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "58b5781bf500492d858aa7b2192e4f12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dcfddc72087476ba762f422cc90a74f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7bb29e13c687446fa2c01fcdcc7f0dcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4dfeaf7d052d409db10f670d3316ebb7",
       "max": 445210460.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0f22d207fc764e7aabad6167413639db",
       "tabbable": null,
       "tooltip": null,
       "value": 445210460.0
      }
     },
     "89ed344fd1d94c8392c1f4605a0f22a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58b5781bf500492d858aa7b2192e4f12",
       "placeholder": "",
       "style": "IPY_MODEL_56316114593a4cc1b39ec4d2bf21340e",
       "tabbable": null,
       "tooltip": null,
       "value": "445M/445M[00:01&lt;00:00,326MB/s]"
      }
     },
     "a10435be735549c1ac1f2a215d6d549a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a23803c761d64f6aadd9dc7df6531b61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1ddf87e42b749e29f0620efa83e2829",
       "max": 787742820.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bd9fc2126f374c53aaa3d47a1c0da8bf",
       "tabbable": null,
       "tooltip": null,
       "value": 787742820.0
      }
     },
     "bd9fc2126f374c53aaa3d47a1c0da8bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c754ba21afd14c2997b890d90a6ab50b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e37037a189d1443cb913951668e7e2fb",
       "placeholder": "",
       "style": "IPY_MODEL_4c6ad99348394c64a8594b7ade8a4ad7",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "cbee3ade3b5e48c6b607beb1c07236ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e37037a189d1443cb913951668e7e2fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4e9ff7b6b114bbeab48e0c215ba9705": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b4d5c6fbbbe448f91a348728faede2c",
       "placeholder": "",
       "style": "IPY_MODEL_cbee3ade3b5e48c6b607beb1c07236ee",
       "tabbable": null,
       "tooltip": null,
       "value": "788M/788M[00:02&lt;00:00,321MB/s]"
      }
     },
     "e6b678ed16ed49068a3841e281cfca91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c754ba21afd14c2997b890d90a6ab50b",
        "IPY_MODEL_a23803c761d64f6aadd9dc7df6531b61",
        "IPY_MODEL_e4e9ff7b6b114bbeab48e0c215ba9705"
       ],
       "layout": "IPY_MODEL_3d815abc77d54a4dbcbdcad5468c1bce",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f1ddf87e42b749e29f0620efa83e2829": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
